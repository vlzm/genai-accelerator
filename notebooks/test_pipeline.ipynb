{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß™ Pipeline Testing Notebook\n",
        "\n",
        "This notebook allows testing all components without running Streamlit.\n",
        "\n",
        "**Structure:**\n",
        "1. Setup & Imports\n",
        "2. Test Models (Database)\n",
        "3. Test Tools (Sanctions, Thresholds)\n",
        "4. Test LLM Service\n",
        "5. Test Full Pipeline (Processor)\n",
        "6. Test RBAC/ABAC (Different Users)\n",
        "7. Test Validation/Guardrails\n",
        "8. Test Scenarios (E2E)\n",
        "\n",
        "**Usage:** Run cells sequentially. Each section is independent after Setup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /Users/vladislav/Documents/vlzm/kyc-analyzer/kyc-analyzer\n"
          ]
        }
      ],
      "source": [
        "# Add project root to path\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Navigate to project root (one level up from notebooks/)\n",
        "# Path().absolute() gets current directory (notebooks/), .parent gets project root\n",
        "PROJECT_ROOT = Path().absolute().parent\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment configured:\n",
            "  ENV: LOCAL\n",
            "  LLM_PROVIDER: openai\n",
            "  DATABASE: app_db @ localhost:5432\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables BEFORE imports\n",
        "import os\n",
        "\n",
        "# Required for local development\n",
        "os.environ.setdefault(\"ENV\", \"LOCAL\")\n",
        "os.environ.setdefault(\"LLM_PROVIDER\", \"openai\")  # or \"openai\", \"azure\", \"anthropic\"\n",
        "os.environ.setdefault(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
        "os.environ.setdefault(\"OLLAMA_MODEL\", \"llama3.2\")\n",
        "\n",
        "# Database (matches docker-compose.yml - service name is \"db\", not \"postgres\")\n",
        "# Run: docker compose up -d db\n",
        "# NOTE: Using = instead of setdefault() to OVERRIDE .env file values\n",
        "os.environ[\"DATABASE_HOST\"] = \"localhost\"\n",
        "os.environ[\"DATABASE_PORT\"] = \"5432\"\n",
        "os.environ[\"DATABASE_NAME\"] = \"app_db\"  # Matches POSTGRES_DB in docker-compose (overrides .env)\n",
        "os.environ[\"DATABASE_USER\"] = \"postgres\"  # Matches POSTGRES_USER in docker-compose\n",
        "os.environ[\"DATABASE_PASSWORD\"] = \"localdevpassword123\"\n",
        "\n",
        "print(\"Environment configured:\")\n",
        "print(f\"  ENV: {os.environ['ENV']}\")\n",
        "print(f\"  LLM_PROVIDER: {os.environ['LLM_PROVIDER']}\")\n",
        "print(f\"  DATABASE: {os.environ['DATABASE_NAME']} @ {os.environ['DATABASE_HOST']}:{os.environ['DATABASE_PORT']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "from app.models import Request, RequestCreate, AnalysisResult, AnalysisOutput\n",
        "from app.database import init_db, get_session\n",
        "from app.services.processor import Processor\n",
        "from app.services.llm_service import get_llm_service\n",
        "from app.services.auth_mock import get_current_user, UserProfile, Permission, MOCK_USERS, ROLE_PERMISSIONS\n",
        "from app.services.validation import run_all_validations\n",
        "from app.services.tools.definitions import TOOL_DEFINITIONS, TOOL_FUNCTIONS, execute_tool\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Test Models (Database)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request fields:\n",
            "  id: typing.Optional[int]\n",
            "  input_text: <class 'str'>\n",
            "  context: typing.Optional[str]\n",
            "  group: <class 'str'>\n",
            "  created_by_user_id: typing.Optional[str]\n",
            "  created_at: <class 'datetime.datetime'>\n",
            "\n",
            "AnalysisResult fields:\n",
            "  id: typing.Optional[int]\n",
            "  request_id: <class 'int'>\n",
            "  score: <class 'int'>\n",
            "  categories: list[str]\n",
            "  summary: <class 'str'>\n",
            "  processed_content: typing.Optional[str]\n",
            "  model_version: <class 'str'>\n",
            "  group: <class 'str'>\n",
            "  analyzed_by_user_id: typing.Optional[str]\n",
            "  llm_trace: <class 'dict'>\n",
            "  human_feedback: typing.Optional[bool]\n",
            "  feedback_comment: typing.Optional[str]\n",
            "  feedback_by_user_id: typing.Optional[str]\n",
            "  feedback_at: typing.Optional[datetime.datetime]\n",
            "  validation_status: <class 'str'>\n",
            "  validation_details: typing.Optional[str]\n",
            "  created_at: <class 'datetime.datetime'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bc/6rm76y3s2f7180l31j70ss7h0000gn/T/ipykernel_7479/571665599.py:3: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use the `model_fields` class property instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  for name, field in Request.__fields__.items():\n",
            "/var/folders/bc/6rm76y3s2f7180l31j70ss7h0000gn/T/ipykernel_7479/571665599.py:7: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use the `model_fields` class property instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  for name, field in AnalysisResult.__fields__.items():\n"
          ]
        }
      ],
      "source": [
        "# Check model fields - verify your schema changes\n",
        "print(\"Request fields:\")\n",
        "for name, field in Request.__fields__.items():\n",
        "    print(f\"  {name}: {field.annotation}\")\n",
        "\n",
        "print(\"\\nAnalysisResult fields:\")\n",
        "for name, field in AnalysisResult.__fields__.items():\n",
        "    print(f\"  {name}: {field.annotation}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Database initialized\n"
          ]
        }
      ],
      "source": [
        "# Initialize database (creates tables if not exist)\n",
        "init_db()\n",
        "print(\"‚úÖ Database initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Test creating a request manually (with rollback - won't pollute DB)\n",
        "# # This is just for testing the model structure\n",
        "# with get_session() as session:\n",
        "#     test_request = Request(\n",
        "#         input_text=\"Test transaction comment\",\n",
        "#         context=\"Testing from notebook\",\n",
        "#         group=\"test_group\",\n",
        "#     )\n",
        "#     session.add(test_request)\n",
        "#     session.flush()  # Get ID without committing\n",
        "    \n",
        "#     print(f\"‚úÖ Created request with ID: {test_request.id}\")\n",
        "#     print(f\"   Input: {test_request.input_text}\")\n",
        "#     print(f\"   Group: {test_request.group}\")\n",
        "    \n",
        "#     session.rollback()\n",
        "#     print(\"   (rolled back - test only)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved request to DB:\n",
            "   ID: 4\n",
            "   Input: Payment for services from ABC Corp, $5,000\n",
            "   Group: default\n"
          ]
        }
      ],
      "source": [
        "# Create a request that WILL be saved to DB (no rollback)\n",
        "with get_session() as session:\n",
        "    saved_request = Request(\n",
        "        input_text=\"Payment for services from ABC Corp, $5,000\",\n",
        "        context=\"Test transaction saved to DB\",\n",
        "        group=\"default\",\n",
        "    )\n",
        "    session.add(saved_request)\n",
        "    # No rollback - this will be committed!\n",
        "    \n",
        "print(f\"‚úÖ Saved request to DB:\")\n",
        "print(f\"   ID: {saved_request.id}\")\n",
        "print(f\"   Input: {saved_request.input_text}\")\n",
        "print(f\"   Group: {saved_request.group}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Found 4 requests in database:\n",
            "\n",
            "  ID: 1\n",
            "    Input: Payment for services from ABC Corp, $5,000...\n",
            "    Group: default\n",
            "    Created: 2026-01-06 21:22:50.713721\n",
            "\n",
            "  ID: 2\n",
            "    Input: Payment for services from ABC Corp, $5,000...\n",
            "    Group: default\n",
            "    Created: 2026-01-06 21:23:04.259890\n",
            "\n",
            "  ID: 3\n",
            "    Input: Payment for services from ABC Corp, $5,000...\n",
            "    Group: default\n",
            "    Created: 2026-01-07 16:17:49.032655\n",
            "\n",
            "  ID: 4\n",
            "    Input: Payment for services from ABC Corp, $5,000...\n",
            "    Group: default\n",
            "    Created: 2026-01-07 16:23:21.330699\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check what's actually in the database\n",
        "from sqlmodel import select\n",
        "\n",
        "with get_session() as session:\n",
        "    # Query all requests\n",
        "    stmt = select(Request)\n",
        "    requests = session.exec(stmt).all()\n",
        "    \n",
        "    print(f\"üìä Found {len(requests)} requests in database:\\n\")\n",
        "    for req in requests:\n",
        "        print(f\"  ID: {req.id}\")\n",
        "        print(f\"    Input: {req.input_text[:60]}...\")\n",
        "        print(f\"    Group: {req.group}\")\n",
        "        print(f\"    Created: {req.created_at}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test Tools (Function Calling)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registered tools: 0\n",
            "‚ÑπÔ∏è No tools defined yet. Add tools in Phase 2.\n",
            "   File: app/services/tools/definitions.py\n",
            "\n",
            "Tool functions available: ['lookup_database', 'validate_data']\n"
          ]
        }
      ],
      "source": [
        "# Check available tools\n",
        "print(f\"Registered tools: {len(TOOL_DEFINITIONS)}\")\n",
        "\n",
        "if TOOL_DEFINITIONS:\n",
        "    for tool in TOOL_DEFINITIONS:\n",
        "        func = tool[\"function\"]\n",
        "        print(f\"\\nüìå {func['name']}\")\n",
        "        print(f\"   Description: {func['description'][:80]}...\")\n",
        "        print(f\"   Parameters: {list(func['parameters']['properties'].keys())}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No tools defined yet. Add tools in Phase 2.\")\n",
        "    print(\"   File: app/services/tools/definitions.py\")\n",
        "\n",
        "print(f\"\\nTool functions available: {list(TOOL_FUNCTIONS.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è Uncomment tool tests after implementing tools in Phase 2\n"
          ]
        }
      ],
      "source": [
        "# Test tools directly (uncomment after implementing in Phase 2)\n",
        "# These tests run WITHOUT LLM - just the tool functions\n",
        "\n",
        "# Example: Test sanctions check\n",
        "# from app.services.tools.sanctions import check_sanctions_list\n",
        "# result = check_sanctions_list(\"Ahmed Ivanov\")\n",
        "# print(\"Sanctions check result:\")\n",
        "# print(result)\n",
        "\n",
        "# Example: Test threshold validation  \n",
        "# from app.services.tools.thresholds import validate_amount_threshold\n",
        "# result = validate_amount_threshold(9500, \"USD\")\n",
        "# print(\"Threshold check result:\")\n",
        "# print(result)\n",
        "\n",
        "print(\"‚ÑπÔ∏è Uncomment tool tests after implementing tools in Phase 2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test LLM Service\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM Provider: openai\n",
            "Model: openai/gpt-5.2\n"
          ]
        }
      ],
      "source": [
        "# Get LLM service instance\n",
        "llm_service = get_llm_service()\n",
        "\n",
        "print(f\"LLM Provider: {llm_service.provider.provider_name}\")\n",
        "print(f\"Model: {llm_service.provider.get_model_version()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing simple analysis...\n",
            "Input: Payment for consulting services from John Smith, amount $5000\n",
            "\n",
            "‚úÖ LLM Response:\n",
            "   Score: 18\n",
            "   Categories: ['Financial Transaction', 'Consulting Services', 'Payment Record', 'Potential Compliance/Accounting']\n",
            "   Reasoning: The input describes a straightforward business payment: a $5,000 payment for consulting services from an individual named John Smith. It contains basic transaction details (payer/payee reference, purp...\n"
          ]
        }
      ],
      "source": [
        "# Test simple analysis (no tools)\n",
        "test_input = \"Payment for consulting services from John Smith, amount $5000\"\n",
        "\n",
        "print(f\"Testing simple analysis...\")\n",
        "print(f\"Input: {test_input}\\n\")\n",
        "\n",
        "try:\n",
        "    response = llm_service.analyze(test_input)\n",
        "    print(\"‚úÖ LLM Response:\")\n",
        "    print(f\"   Score: {response.score}\")\n",
        "    print(f\"   Categories: {response.categories}\")\n",
        "    print(f\"   Reasoning: {response.reasoning[:200]}...\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"   Make sure LLM provider is running (ollama, openai key, etc.)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è No tools defined yet. Agent mode test skipped.\n",
            "   Define TOOL_DEFINITIONS in app/services/tools/definitions.py\n"
          ]
        }
      ],
      "source": [
        "# Test analysis WITH tools (agent mode)\n",
        "# Only works if TOOL_DEFINITIONS is not empty\n",
        "\n",
        "if TOOL_DEFINITIONS:\n",
        "    test_input = \"Wire transfer from Ahmed Ivanov for $9500 USD\"\n",
        "    \n",
        "    print(f\"Testing agent mode with tools...\")\n",
        "    print(f\"Input: {test_input}\\n\")\n",
        "    \n",
        "    try:\n",
        "        response = llm_service.analyze_with_tools(test_input)\n",
        "        print(\"‚úÖ Agent Response:\")\n",
        "        print(f\"   Score: {response.score}\")\n",
        "        print(f\"   Categories: {response.categories}\")\n",
        "        print(f\"   Tools used: {response.tools_used}\")\n",
        "        print(f\"   Reasoning: {response.reasoning[:300]}...\")\n",
        "        \n",
        "        if response.trace:\n",
        "            print(f\"\\n   Trace keys: {list(response.trace.keys())}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No tools defined yet. Agent mode test skipped.\")\n",
        "    print(\"   Define TOOL_DEFINITIONS in app/services/tools/definitions.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test Full Pipeline (Processor)\n",
        "\n",
        "This is what Streamlit does behind the scenes - the complete analysis flow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing as user: usr_003 (role: UserRole.ANALYST)\n",
            "  Permissions: ['analyze', 'view_sensitive', 'view']\n",
            "  Group: group_a\n"
          ]
        }
      ],
      "source": [
        "# Get a test user for RBAC\n",
        "user = get_current_user(\"analyst_a\")\n",
        "print(f\"Testing as user: {user.id} (role: {user.role})\")\n",
        "print(f\"  Permissions: {[p.value for p in ROLE_PERMISSIONS.get(user.role, set())]}\")\n",
        "print(f\"  Group: {user.group.value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing request...\n",
            "  Input: International wire transfer from Elena Volkova for real estate purchase, amount $150,000\n",
            "  Context: High-value cross-border transaction\n",
            "\n",
            "‚úÖ Pipeline completed!\n",
            "\n",
            "üìã Request (ID: 5)\n",
            "   Input: International wire transfer from Elena Volkova for real estate purchase, amount ...\n",
            "   Group: group_a\n",
            "\n",
            "üìä Analysis Result (ID: 1)\n",
            "   Score: 62\n",
            "   Categories: ['Financial Transaction', 'Cross-Border Payment', 'Real Estate Purchase', 'High-Value Transaction', 'AML/KYC Risk Indicator']\n",
            "   Summary: The input describes an international wire transfer from an individual (Elena Volkova) for a real estate purchase in the amount of $150,000, explicitly noted as a high-value cross-border transaction. T...\n",
            "   Model: openai/gpt-5.2\n",
            "   Validation: PASS\n",
            "\n",
            "üîç LLM Trace:\n",
            "   Keys: ['started_at', 'model', 'mode', 'input', 'completed_at', 'raw_response_preview']\n"
          ]
        }
      ],
      "source": [
        "# Run full analysis pipeline\n",
        "test_data = RequestCreate(\n",
        "    input_text=\"International wire transfer from Elena Volkova for real estate purchase, amount $150,000\",\n",
        "    context=\"High-value cross-border transaction\",\n",
        "    group=\"default\",\n",
        ")\n",
        "\n",
        "print(f\"Processing request...\")\n",
        "print(f\"  Input: {test_data.input_text}\")\n",
        "print(f\"  Context: {test_data.context}\\n\")\n",
        "\n",
        "with get_session() as session:\n",
        "    processor = Processor(session, user=user)\n",
        "    \n",
        "    try:\n",
        "        request, result = processor.process_request(test_data)\n",
        "        \n",
        "        print(\"‚úÖ Pipeline completed!\")\n",
        "        print(f\"\\nüìã Request (ID: {request.id})\")\n",
        "        print(f\"   Input: {request.input_text[:80]}...\")\n",
        "        print(f\"   Group: {request.group}\")\n",
        "        \n",
        "        print(f\"\\nüìä Analysis Result (ID: {result.id})\")\n",
        "        print(f\"   Score: {result.score}\")\n",
        "        print(f\"   Categories: {result.categories}\")\n",
        "        print(f\"   Summary: {result.summary[:200]}...\")\n",
        "        print(f\"   Model: {result.model_version}\")\n",
        "        print(f\"   Validation: {result.validation_status}\")\n",
        "        \n",
        "        if result.llm_trace:\n",
        "            print(f\"\\nüîç LLM Trace:\")\n",
        "            print(f\"   Keys: {list(result.llm_trace.keys())}\")\n",
        "            if \"tools_called\" in result.llm_trace:\n",
        "                print(f\"   Tools called: {result.llm_trace['tools_called']}\")\n",
        "                \n",
        "    except PermissionError as e:\n",
        "        print(f\"‚ùå Permission denied: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'simple'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.llm_trace['mode']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test RBAC/ABAC (Different Users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'admin_default': UserProfile(id='usr_001', username='Alice Administrator', email='alice.admin@example.com', role=<UserRole.ADMIN: 'admin'>, group=<Group.DEFAULT: 'default'>),\n",
              " 'senior_default': UserProfile(id='usr_002', username='Bob Senior Analyst', email='bob.senior@example.com', role=<UserRole.SENIOR_ANALYST: 'senior_analyst'>, group=<Group.DEFAULT: 'default'>),\n",
              " 'analyst_a': UserProfile(id='usr_003', username='Carol Analyst (Group A)', email='carol.analyst@example.com', role=<UserRole.ANALYST: 'analyst'>, group=<Group.GROUP_A: 'group_a'>),\n",
              " 'analyst_b': UserProfile(id='usr_004', username='David Analyst (Group B)', email='david.analyst@example.com', role=<UserRole.ANALYST: 'analyst'>, group=<Group.GROUP_B: 'group_b'>),\n",
              " 'viewer_a': UserProfile(id='usr_005', username='Eve Viewer (Group A)', email='eve.viewer@example.com', role=<UserRole.VIEWER: 'viewer'>, group=<Group.GROUP_A: 'group_a'>)}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MOCK_USERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available mock users:\n",
            "\n",
            "  admin_default:\n",
            "    Role: UserRole.ADMIN\n",
            "  Permissions: ['analyze', 'view_sensitive', 'export_data', 'view_all_groups', 'manage_users', 'view']\n",
            "    Groups: Group.DEFAULT\n",
            "\n",
            "  senior_default:\n",
            "    Role: UserRole.SENIOR_ANALYST\n",
            "  Permissions: ['analyze', 'view_sensitive', 'export_data', 'view_all_groups', 'view']\n",
            "    Groups: Group.DEFAULT\n",
            "\n",
            "  analyst_a:\n",
            "    Role: UserRole.ANALYST\n",
            "  Permissions: ['analyze', 'view_sensitive', 'view']\n",
            "    Groups: Group.GROUP_A\n",
            "\n",
            "  analyst_b:\n",
            "    Role: UserRole.ANALYST\n",
            "  Permissions: ['analyze', 'view_sensitive', 'view']\n",
            "    Groups: Group.GROUP_B\n",
            "\n",
            "  viewer_a:\n",
            "    Role: UserRole.VIEWER\n",
            "  Permissions: ['view']\n",
            "    Groups: Group.GROUP_A\n"
          ]
        }
      ],
      "source": [
        "# List all available mock users\n",
        "print(\"Available mock users:\")\n",
        "for user_key, user in MOCK_USERS.items():\n",
        "    print(f\"\\n  {user_key}:\")\n",
        "    print(f\"    Role: {user.role}\")\n",
        "    print(f\"  Permissions: {[p.value for p in ROLE_PERMISSIONS.get(user.role, set())]}\")\n",
        "    print(f\"    Groups: {user.group}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "set[app.services.auth_mock.Permission]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from app.services.auth_mock import Permission\n",
        "set[Permission]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing as VIEWER: usr_005\n",
            "  Permissions: ['view']\n",
            "‚úÖ Correctly blocked: Access denied. User 'Eve Viewer (Group A)' with role 'viewer' does not have permission 'analyze'.\n"
          ]
        }
      ],
      "source": [
        "# Test RBAC - viewer should NOT be able to analyze\n",
        "from app.services.auth_mock import Permission\n",
        "\n",
        "\n",
        "viewer = get_current_user(\"viewer_a\")\n",
        "print(f\"Testing as VIEWER: {viewer.id}\")\n",
        "print(f\"  Permissions: {[p.value for p in ROLE_PERMISSIONS.get(user.role, set[Permission]())]}\")\n",
        "\n",
        "with get_session() as session:\n",
        "    processor = Processor(session, user=viewer)\n",
        "    \n",
        "    try:\n",
        "        request, result = processor.process_request(RequestCreate(\n",
        "            input_text=\"Test transaction\",\n",
        "        ))\n",
        "        print(\"‚ùå Should have failed! Viewer shouldn't be able to analyze.\")\n",
        "    except PermissionError as e:\n",
        "        print(f\"‚úÖ Correctly blocked: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyst A groups: Group.GROUP_A\n",
            "Analyst B groups: Group.GROUP_B\n",
            "\n",
            "Analyst A sees 1 results\n",
            "Analyst B sees 0 results\n",
            "Analyst A result groups: {'group_a'}\n"
          ]
        }
      ],
      "source": [
        "# Test ABAC - analysts only see their group's data\n",
        "analyst_a = get_current_user(\"analyst_a\")\n",
        "analyst_b = get_current_user(\"analyst_b\")\n",
        "\n",
        "print(f\"Analyst A groups: {analyst_a.group}\")\n",
        "print(f\"Analyst B groups: {analyst_b.group}\")\n",
        "\n",
        "with get_session() as session:\n",
        "    processor_a = Processor(session, user=analyst_a)\n",
        "    results_a = processor_a.get_recent_results(limit=10)\n",
        "    \n",
        "    processor_b = Processor(session, user=analyst_b)\n",
        "    results_b = processor_b.get_recent_results(limit=10)\n",
        "    \n",
        "    print(f\"\\nAnalyst A sees {len(results_a)} results\")\n",
        "    print(f\"Analyst B sees {len(results_b)} results\")\n",
        "    \n",
        "    if results_a:\n",
        "        print(f\"Analyst A result groups: {set(r.group for r in results_a)}\")\n",
        "    if results_b:\n",
        "        print(f\"Analyst B result groups: {set(r.group for r in results_b)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test Validation / Guardrails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation status: PASS\n",
            "Details: None\n",
            "Passed: True\n"
          ]
        }
      ],
      "source": [
        "# Test validation functions directly\n",
        "from app.services.llm_service import LLMResponse\n",
        "\n",
        "# Create mock LLM response WITH potential PII leakage\n",
        "mock_response = LLMResponse(\n",
        "    score=75,\n",
        "    categories=[\"suspicious\", \"high_value\"],\n",
        "    reasoning=\"This transaction shows signs of potential money laundering. The sender's SSN is 123-45-6789.\",\n",
        ")\n",
        "\n",
        "original_input = \"Wire transfer from John Smith\"\n",
        "\n",
        "result = run_all_validations(\n",
        "    response_text=mock_response.reasoning,\n",
        "    score=mock_response.score,              \n",
        "    categories=mock_response.categories\n",
        ")\n",
        "\n",
        "print(f\"Validation status: {result.status}\")\n",
        "print(f\"Details: {result.details}\")\n",
        "print(f\"Passed: {result.passed}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Scenarios (E2E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined 4 test scenarios:\n",
            "  1. Clean Transaction - Expected: LOW\n",
            "  2. Near Threshold (Structuring) - Expected: MEDIUM\n",
            "  3. Sanctions Match - Expected: CRITICAL\n",
            "  4. PEP Transaction - Expected: HIGH\n"
          ]
        }
      ],
      "source": [
        "# Define test scenarios for the KYC/AML case\n",
        "TEST_SCENARIOS = [\n",
        "    {\n",
        "        \"name\": \"Clean Transaction\",\n",
        "        \"input\": \"Payment for consulting services from ABC Corp, $2,500\",\n",
        "        \"expected_risk\": \"LOW\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Near Threshold (Structuring)\",\n",
        "        \"input\": \"Cash deposit $9,500 - monthly savings\",\n",
        "        \"expected_risk\": \"MEDIUM\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Sanctions Match\",\n",
        "        \"input\": \"Wire transfer from Ahmed Ivanov for equipment purchase, $15,000\",\n",
        "        \"expected_risk\": \"CRITICAL\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"PEP Transaction\",\n",
        "        \"input\": \"Donation from Elena Volkova for charity event, $50,000\",\n",
        "        \"expected_risk\": \"HIGH\",\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"Defined {len(TEST_SCENARIOS)} test scenarios:\")\n",
        "for i, scenario in enumerate(TEST_SCENARIOS, 1):\n",
        "    print(f\"  {i}. {scenario['name']} - Expected: {scenario['expected_risk']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running test scenarios...\n",
            "\n",
            "‚úÖ Clean Transaction\n",
            "   Expected: LOW, Got: LOW (score: 8)\n",
            "   Categories: ['Financial Transaction', 'Consulting Services', 'Business Payment', 'Low Risk / Routine Activity']\n",
            "   Validation: PASS\n",
            "\n",
            "‚ö†Ô∏è Near Threshold (Structuring)\n",
            "   Expected: MEDIUM, Got: HIGH (score: 58)\n",
            "   Categories: ['Financial transaction', 'Cash deposit', 'AML/CTF risk', 'Structuring / smurfing (near reporting threshold)', 'Transaction monitoring']\n",
            "   Validation: PASS\n",
            "\n",
            "‚ö†Ô∏è Sanctions Match\n",
            "   Expected: CRITICAL, Got: HIGH (score: 72)\n",
            "   Categories: ['Financial Transaction', 'Sanctions Screening / Potential Match', 'KYC / Counterparty Identification', 'Trade / Equipment Purchase', 'AML Risk Review']\n",
            "   Validation: PASS\n",
            "\n",
            "‚úÖ PEP Transaction\n",
            "   Expected: HIGH, Got: HIGH (score: 72)\n",
            "   Categories: ['Financial Transaction', 'Charitable Donation', 'PEP (Politically Exposed Person) Screening', 'AML/CTF Risk', 'KYC/Source of Funds Verification']\n",
            "   Validation: PASS\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run all test scenarios\n",
        "def run_test_scenario(scenario: dict, user: UserProfile):\n",
        "    \"\"\"Run a single test scenario and return results.\"\"\"\n",
        "    with get_session() as session:\n",
        "        processor = Processor(session, user=user)\n",
        "        \n",
        "        request_data = RequestCreate(\n",
        "            input_text=scenario[\"input\"],\n",
        "            context=f\"Test: {scenario['name']}\",\n",
        "        )\n",
        "        \n",
        "        request, result = processor.process_request(request_data)\n",
        "        \n",
        "        return {\n",
        "            \"name\": scenario[\"name\"],\n",
        "            \"expected\": scenario[\"expected_risk\"],\n",
        "            \"actual_score\": result.score,\n",
        "            \"categories\": result.categories,\n",
        "            \"validation\": result.validation_status,\n",
        "            \"summary\": result.summary[:100] + \"...\",\n",
        "        }\n",
        "\n",
        "# Run scenarios\n",
        "user = get_current_user(\"analyst_a\")\n",
        "\n",
        "print(\"Running test scenarios...\\n\")\n",
        "for scenario in TEST_SCENARIOS:\n",
        "    try:\n",
        "        result = run_test_scenario(scenario, user)\n",
        "        \n",
        "        # Determine risk level from score\n",
        "        score = result[\"actual_score\"]\n",
        "        if score <= 25:\n",
        "            actual_level = \"LOW\"\n",
        "        elif score <= 50:\n",
        "            actual_level = \"MEDIUM\"\n",
        "        elif score <= 75:\n",
        "            actual_level = \"HIGH\"\n",
        "        else:\n",
        "            actual_level = \"CRITICAL\"\n",
        "        \n",
        "        match = \"‚úÖ\" if actual_level == result[\"expected\"] else \"‚ö†Ô∏è\"\n",
        "        \n",
        "        print(f\"{match} {result['name']}\")\n",
        "        print(f\"   Expected: {result['expected']}, Got: {actual_level} (score: {score})\")\n",
        "        print(f\"   Categories: {result['categories']}\")\n",
        "        print(f\"   Validation: {result['validation']}\")\n",
        "        print()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {scenario['name']}: {e}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Debug Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last 5 analysis results:\n",
            "\n",
            "ID: 5 | Score: 72 | Status: PASS\n",
            "   Categories: ['Financial Transaction', 'Charitable Donation', 'PEP (Politically Exposed Person) Screening', 'AML/CTF Risk', 'KYC/Source of Funds Verification']\n",
            "   Created: 2026-01-07 19:33:13.796322\n",
            "\n",
            "ID: 4 | Score: 72 | Status: PASS\n",
            "   Categories: ['Financial Transaction', 'Sanctions Screening / Potential Match', 'KYC / Counterparty Identification', 'Trade / Equipment Purchase', 'AML Risk Review']\n",
            "   Created: 2026-01-07 19:33:03.075626\n",
            "\n",
            "ID: 3 | Score: 58 | Status: PASS\n",
            "   Categories: ['Financial transaction', 'Cash deposit', 'AML/CTF risk', 'Structuring / smurfing (near reporting threshold)', 'Transaction monitoring']\n",
            "   Created: 2026-01-07 19:32:50.012867\n",
            "\n",
            "ID: 2 | Score: 8 | Status: PASS\n",
            "   Categories: ['Financial Transaction', 'Consulting Services', 'Business Payment', 'Low Risk / Routine Activity']\n",
            "   Created: 2026-01-07 19:32:42.380756\n",
            "\n",
            "ID: 1 | Score: 62 | Status: PASS\n",
            "   Categories: ['Financial Transaction', 'Cross-Border Payment', 'Real Estate Purchase', 'High-Value Transaction', 'AML/KYC Risk Indicator']\n",
            "   Created: 2026-01-07 16:30:38.015508\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Helper: View recent results from DB\n",
        "from sqlmodel import select\n",
        "\n",
        "with get_session() as session:\n",
        "    stmt = select(AnalysisResult).order_by(AnalysisResult.created_at.desc()).limit(5)\n",
        "    results = session.exec(stmt).all()\n",
        "    \n",
        "    print(f\"Last {len(results)} analysis results:\\n\")\n",
        "    for r in results:\n",
        "        print(f\"ID: {r.id} | Score: {r.score} | Status: {r.validation_status}\")\n",
        "        print(f\"   Categories: {r.categories}\")\n",
        "        print(f\"   Created: {r.created_at}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM Trace for result 1:\n",
            "{\n",
            "  \"started_at\": \"2026-01-07T16:30:29.589670\",\n",
            "  \"model\": \"openai/gpt-5.2\",\n",
            "  \"mode\": \"simple\",\n",
            "  \"input\": {\n",
            "    \"input_text\": \"International wire transfer from Elena Volkova for real estate purchase, amount $150,000\",\n",
            "    \"context\": \"High-value cross-border transaction\"\n",
            "  },\n",
            "  \"completed_at\": \"2026-01-07T16:30:38.013203\",\n",
            "  \"raw_response_preview\": \"{\\n  \\\"score\\\": 62,\\n  \\\"categories\\\": [\\n    \\\"Financial Transaction\\\",\\n    \\\"Cross-Border Payment\\\",\\n    \\\"Real Estate Purchase\\\",\\n    \\\"High-Value Transaction\\\",\\n    \\\"AML/KYC Risk Indicator\\\"\\n  ],\\n  \\\"summary\\\": \\\"The input describes an international wire transfer from an individual (Elena Volkova) for a real estate purchase in the amount of $150,000, explicitly noted as a high-value cross-border transaction. This combination (cross-border + real estate + relatively large amount) is a common AML/CTF risk indica\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Helper: View LLM trace for a specific result\n",
        "import json\n",
        "\n",
        "result_id = 1  # Change this to inspect different results\n",
        "\n",
        "with get_session() as session:\n",
        "    result = session.get(AnalysisResult, result_id)\n",
        "    \n",
        "    if result and result.llm_trace:\n",
        "        print(f\"LLM Trace for result {result_id}:\")\n",
        "        print(json.dumps(result.llm_trace, indent=2, default=str))\n",
        "    else:\n",
        "        print(f\"No trace found for result {result_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All test data cleared\n"
          ]
        }
      ],
      "source": [
        "# Helper: Clear all test data (use carefully!)\n",
        "# Uncomment to run\n",
        "\n",
        "from sqlmodel import text\n",
        "with get_session() as session:\n",
        "    session.exec(text(\"DELETE FROM analysis_results\"))\n",
        "    session.exec(text(\"DELETE FROM requests\"))\n",
        "    print(\"‚úÖ All test data cleared\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù Quick Reference\n",
        "\n",
        "### Before Interview:\n",
        "1. `docker compose up -d db` - Start database (service name is **db**, not postgres)\n",
        "2. Check LLM provider (Ollama running OR API key set)\n",
        "3. Run Setup cells (1.1 - 1.3)\n",
        "\n",
        "### During Interview - Quick Validation:\n",
        "| Phase | Test Section |\n",
        "|-------|-------------|\n",
        "| Phase 1 (Models) | Section 2 |\n",
        "| Phase 2 (Tools) | Section 3 |\n",
        "| Phase 3 (Prompts) | Sections 4-5 |\n",
        "| Phase 4 (Validation) | Section 7 |\n",
        "| Phase 5 (Processor) | Section 5 |\n",
        "| Phase 6 (UI) | Streamlit browser |\n",
        "\n",
        "### Hotkeys:\n",
        "- `Shift+Enter` - Run cell and move to next\n",
        "- `Ctrl+Enter` - Run cell and stay\n",
        "- `Esc + A` - Insert cell above\n",
        "- `Esc + B` - Insert cell below\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
