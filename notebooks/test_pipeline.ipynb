{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß™ Pipeline Testing Notebook\n",
        "\n",
        "This notebook allows testing all components without running Streamlit.\n",
        "\n",
        "**Structure:**\n",
        "1. Setup & Imports\n",
        "2. Test Models (Database)\n",
        "3. Test Tools (Restrictions, Classification)\n",
        "4. Test LLM Service\n",
        "5. Test Full Pipeline (Processor)\n",
        "6. Test RBAC/ABAC (Different Users)\n",
        "7. Test Validation/Guardrails\n",
        "8. Test Scenarios (E2E)\n",
        "\n",
        "**Usage:** Run cells sequentially. Each section is independent after Setup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\Users\\zamko\\Documents\\vlzm\\kyc-analyzer\n"
          ]
        }
      ],
      "source": [
        "# Add project root to path\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Navigate to project root (one level up from notebooks/)\n",
        "# Path().absolute() gets current directory (notebooks/), .parent gets project root\n",
        "PROJECT_ROOT = Path().absolute().parent\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment configured:\n",
            "  ENV: LOCAL\n",
            "  LLM_PROVIDER: openai\n",
            "  DATABASE: app_db @ localhost:5432\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables BEFORE imports\n",
        "import os\n",
        "\n",
        "# Required for local development\n",
        "os.environ.setdefault(\"ENV\", \"LOCAL\")\n",
        "os.environ.setdefault(\"LLM_PROVIDER\", \"openai\")  # or \"openai\", \"azure\", \"anthropic\"\n",
        "os.environ.setdefault(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
        "os.environ.setdefault(\"OLLAMA_MODEL\", \"llama3.2\")\n",
        "\n",
        "# Database (matches docker-compose.yml - service name is \"db\", not \"postgres\")\n",
        "# Run: docker compose up -d db\n",
        "# NOTE: Using = instead of setdefault() to OVERRIDE .env file values\n",
        "os.environ[\"DATABASE_HOST\"] = \"localhost\"\n",
        "os.environ[\"DATABASE_PORT\"] = \"5432\"\n",
        "os.environ[\"DATABASE_NAME\"] = \"app_db\"  # Matches POSTGRES_DB in docker-compose (overrides .env)\n",
        "os.environ[\"DATABASE_USER\"] = \"postgres\"  # Matches POSTGRES_USER in docker-compose\n",
        "os.environ[\"DATABASE_PASSWORD\"] = \"localdevpassword123\"\n",
        "\n",
        "print(\"Environment configured:\")\n",
        "print(f\"  ENV: {os.environ['ENV']}\")\n",
        "print(f\"  LLM_PROVIDER: {os.environ['LLM_PROVIDER']}\")\n",
        "print(f\"  DATABASE: {os.environ['DATABASE_NAME']} @ {os.environ['DATABASE_HOST']}:{os.environ['DATABASE_PORT']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "from app.models import Request, RequestCreate, AnalysisResult, AnalysisOutput\n",
        "from app.database import init_db, get_session\n",
        "from app.services.processor import Processor\n",
        "from app.services.llm_service import get_llm_service\n",
        "from app.services.auth_mock import get_current_user, UserProfile, Permission, MOCK_USERS, ROLE_PERMISSIONS\n",
        "from app.services.validation import run_all_validations\n",
        "from app.services.tools.definitions import TOOL_DEFINITIONS, TOOL_FUNCTIONS, execute_tool\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Test Models (Database)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request fields:\n",
            "  id: typing.Optional[int]\n",
            "  input_text: <class 'str'>\n",
            "  context: typing.Optional[str]\n",
            "  group: <class 'str'>\n",
            "  created_by_user_id: typing.Optional[str]\n",
            "  created_at: <class 'datetime.datetime'>\n",
            "\n",
            "AnalysisResult fields:\n",
            "  id: typing.Optional[int]\n",
            "  request_id: <class 'int'>\n",
            "  score: <class 'int'>\n",
            "  categories: list[str]\n",
            "  summary: <class 'str'>\n",
            "  processed_content: typing.Optional[str]\n",
            "  model_version: <class 'str'>\n",
            "  group: <class 'str'>\n",
            "  analyzed_by_user_id: typing.Optional[str]\n",
            "  llm_trace: <class 'dict'>\n",
            "  human_feedback: typing.Optional[bool]\n",
            "  feedback_comment: typing.Optional[str]\n",
            "  feedback_by_user_id: typing.Optional[str]\n",
            "  feedback_at: typing.Optional[datetime.datetime]\n",
            "  validation_status: <class 'str'>\n",
            "  validation_details: typing.Optional[str]\n",
            "  embedding: typing.Optional[typing.List[float]]\n",
            "  created_at: <class 'datetime.datetime'>\n"
          ]
        }
      ],
      "source": [
        "# Check model fields - verify your schema changes\n",
        "print(\"Request fields:\")\n",
        "for name, field in Request.model_fields.items():\n",
        "    print(f\"  {name}: {field.annotation}\")\n",
        "\n",
        "print(\"\\nAnalysisResult fields:\")\n",
        "for name, field in AnalysisResult.model_fields.items():\n",
        "    print(f\"  {name}: {field.annotation}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Database initialized\n"
          ]
        }
      ],
      "source": [
        "# Initialize database (creates tables if not exist)\n",
        "init_db()\n",
        "print(\"‚úÖ Database initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created request with ID: 5\n",
            "   Input: Test document content\n",
            "   Group: test_group\n",
            "   (rolled back - test only)\n"
          ]
        }
      ],
      "source": [
        "# Test creating a request manually (with rollback - won't pollute DB)\n",
        "# This is just for testing the model structure\n",
        "with get_session() as session:\n",
        "    test_request = Request(\n",
        "        input_text=\"Test document content\",\n",
        "        context=\"Testing from notebook\",\n",
        "        group=\"test_group\",\n",
        "    )\n",
        "    session.add(test_request)\n",
        "    session.flush()  # Get ID without committing\n",
        "    \n",
        "    print(f\"‚úÖ Created request with ID: {test_request.id}\")\n",
        "    print(f\"   Input: {test_request.input_text}\")\n",
        "    print(f\"   Group: {test_request.group}\")\n",
        "    \n",
        "    session.rollback()\n",
        "    print(\"   (rolled back - test only)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved request to DB:\n",
            "   ID: 6\n",
            "   Input: Customer service email from John Smith at ABC Corp regarding account inquiry\n",
            "   Group: default\n"
          ]
        }
      ],
      "source": [
        "# Create a request that WILL be saved to DB (no rollback)\n",
        "with get_session() as session:\n",
        "    saved_request = Request(\n",
        "        input_text=\"Customer service email from John Smith at ABC Corp regarding account inquiry\",\n",
        "        context=\"Test document saved to DB\",\n",
        "        group=\"default\",\n",
        "    )\n",
        "    session.add(saved_request)\n",
        "    # No rollback - this will be committed!\n",
        "    \n",
        "print(f\"‚úÖ Saved request to DB:\")\n",
        "print(f\"   ID: {saved_request.id}\")\n",
        "print(f\"   Input: {saved_request.input_text}\")\n",
        "print(f\"   Group: {saved_request.group}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Found 4 requests in database:\n",
            "\n",
            "  ID: 1\n",
            "    Input: Customer John Smith requested password reset for account A12...\n",
            "    Group: group_a\n",
            "    Created: 2026-01-09 19:23:56.431698\n",
            "\n",
            "  ID: 2\n",
            "    Input: Suspicious login attempt detected for user account from unkn...\n",
            "    Group: group_a\n",
            "    Created: 2026-01-09 19:24:15.013165\n",
            "\n",
            "  ID: 4\n",
            "    Input: Customer service email from John Smith at ABC Corp regarding...\n",
            "    Group: default\n",
            "    Created: 2026-01-09 19:43:08.568944\n",
            "\n",
            "  ID: 6\n",
            "    Input: Customer service email from John Smith at ABC Corp regarding...\n",
            "    Group: default\n",
            "    Created: 2026-01-09 19:48:01.345932\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check what's actually in the database\n",
        "from sqlmodel import select\n",
        "\n",
        "with get_session() as session:\n",
        "    # Query all requests\n",
        "    stmt = select(Request)\n",
        "    requests = session.exec(stmt).all()\n",
        "    \n",
        "    print(f\"üìä Found {len(requests)} requests in database:\\n\")\n",
        "    for req in requests:\n",
        "        print(f\"  ID: {req.id}\")\n",
        "        print(f\"    Input: {req.input_text[:60]}...\")\n",
        "        print(f\"    Group: {req.group}\")\n",
        "        print(f\"    Created: {req.created_at}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test Tools (Function Calling)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registered tools: 3\n",
            "\n",
            "üìå get_current_time\n",
            "   Description: Returns the current date and time in ISO format. Use this when you need to know ...\n",
            "   Parameters: ['timezone']\n",
            "\n",
            "üìå calculate\n",
            "   Description: Performs arithmetic calculations. Supports basic operations: addition (+), subtr...\n",
            "   Parameters: ['expression']\n",
            "\n",
            "üìå lookup_database\n",
            "   Description: Looks up information in the database by query string. Use this when you need to ...\n",
            "   Parameters: ['query', 'table']\n",
            "\n",
            "Tool functions available: ['get_current_time', 'calculate', 'lookup_database']\n"
          ]
        }
      ],
      "source": [
        "# Check available tools\n",
        "print(f\"Registered tools: {len(TOOL_DEFINITIONS)}\")\n",
        "\n",
        "if TOOL_DEFINITIONS:\n",
        "    for tool in TOOL_DEFINITIONS:\n",
        "        func = tool[\"function\"]\n",
        "        print(f\"\\nüìå {func['name']}\")\n",
        "        print(f\"   Description: {func['description'][:80]}...\")\n",
        "        print(f\"   Parameters: {list(func['parameters']['properties'].keys())}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No tools defined yet. Add tools in Phase 2.\")\n",
        "    print(\"   File: app/services/tools/definitions.py\")\n",
        "\n",
        "print(f\"\\nTool functions available: {list(TOOL_FUNCTIONS.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è Uncomment tool tests after implementing tools in Phase 2\n"
          ]
        }
      ],
      "source": [
        "# Test tools directly (uncomment after implementing in Phase 2)\n",
        "# These tests run WITHOUT LLM - just the tool functions\n",
        "\n",
        "# Example: Test restricted entity check\n",
        "# from app.services.tools.restrictions import check_restricted_list\n",
        "# result = check_restricted_list(\"Ahmed Ivanov\")\n",
        "# print(\"Restricted entity check result:\")\n",
        "# print(result)\n",
        "\n",
        "# Example: Test data classification validation  \n",
        "# from app.services.tools.classification import validate_data_classification\n",
        "# result = validate_data_classification(\"confidential\", \"internal\")\n",
        "# print(\"Data classification check result:\")\n",
        "# print(result)\n",
        "\n",
        "print(\"‚ÑπÔ∏è Uncomment tool tests after implementing tools in Phase 2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test LLM Service\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM Provider: openai\n",
            "Model: openai/gpt-5.2\n"
          ]
        }
      ],
      "source": [
        "# Get LLM service instance\n",
        "llm_service = get_llm_service()\n",
        "\n",
        "print(f\"LLM Provider: {llm_service.provider.provider_name}\")\n",
        "print(f\"Model: {llm_service.provider.get_model_version()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing simple analysis...\n",
            "Input: Customer support email from John Smith requesting account information update\n",
            "\n",
            "‚úÖ LLM Response:\n",
            "   Score: 18\n",
            "   Categories: ['Customer Support', 'Account Management', 'Account Information Update Request', 'Potential PII (Names/Identifiers)']\n",
            "   Reasoning: The input is a brief description of a customer support email from an individual (John Smith) requesting an account information update. No actual email body, account identifiers, credentials, or sensit...\n"
          ]
        }
      ],
      "source": [
        "# Test simple analysis (no tools)\n",
        "test_input = \"Customer support email from John Smith requesting account information update\"\n",
        "\n",
        "print(f\"Testing simple analysis...\")\n",
        "print(f\"Input: {test_input}\\n\")\n",
        "\n",
        "try:\n",
        "    response = llm_service.analyze(test_input)\n",
        "    print(\"‚úÖ LLM Response:\")\n",
        "    print(f\"   Score: {response.score}\")\n",
        "    print(f\"   Categories: {response.categories}\")\n",
        "    print(f\"   Reasoning: {response.reasoning[:200]}...\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"   Make sure LLM provider is running (ollama, openai key, etc.)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'function': {'name': 'get_current_time',\n",
              "   'description': 'Returns the current date and time in ISO format. Use this when you need to know the current time or date for time-sensitive analysis or logging purposes.',\n",
              "   'parameters': {'type': 'object',\n",
              "    'properties': {'timezone': {'type': 'string',\n",
              "      'description': \"Optional timezone name (e.g., 'UTC', 'US/Eastern'). Defaults to UTC.\"}},\n",
              "    'required': []}}},\n",
              " {'type': 'function',\n",
              "  'function': {'name': 'calculate',\n",
              "   'description': 'Performs arithmetic calculations. Supports basic operations: addition (+), subtraction (-), multiplication (*), division (/), and exponentiation (**). Use this to compute numeric values during analysis.',\n",
              "   'parameters': {'type': 'object',\n",
              "    'properties': {'expression': {'type': 'string',\n",
              "      'description': \"Mathematical expression to evaluate (e.g., '100 * 1.15', '(50 + 30) / 2')\"}},\n",
              "    'required': ['expression']}}},\n",
              " {'type': 'function',\n",
              "  'function': {'name': 'lookup_database',\n",
              "   'description': 'Looks up information in the database by query string. Use this when you need to verify or retrieve data records. Returns matching records or indicates if nothing was found.',\n",
              "   'parameters': {'type': 'object',\n",
              "    'properties': {'query': {'type': 'string',\n",
              "      'description': 'The search query or entity name to look up'},\n",
              "     'table': {'type': 'string',\n",
              "      'description': 'Optional: specific table/collection to search in'}},\n",
              "    'required': ['query']}}}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TOOL_DEFINITIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing agent mode with tools...\n",
            "Input: Sum 100, 200, and 300and you will find how much money i am sending to you\n",
            "\n",
            "‚úÖ Agent Response:\n",
            "   Score: 18\n",
            "   Categories: ['financial_transaction', 'arithmetic_request', 'informal_message']\n",
            "   Tools used: ['calculate']\n",
            "   Reasoning: The text asks the reader to add 100, 200, and 300 to determine the amount of money being sent. Using the calculation tool, 100 + 200 + 300 = 600. The content implies a monetary transfer but provides no payment method, personal data, threats, or coercion. Primary theme is a simple arithmetic-based st...\n",
            "\n",
            "   Trace keys: ['started_at', 'model', 'mode', 'input', 'tool_calls', 'total_iterations', 'completed_at']\n"
          ]
        }
      ],
      "source": [
        "# Test analysis WITH tools (agent mode)\n",
        "# Only works if TOOL_DEFINITIONS is not empty\n",
        "\n",
        "if TOOL_DEFINITIONS:\n",
        "    test_input = \"Sum 100, 200, and 300and you will find how much money i am sending to you\"\n",
        "    \n",
        "    print(f\"Testing agent mode with tools...\")\n",
        "    print(f\"Input: {test_input}\\n\")\n",
        "    \n",
        "    try:\n",
        "        response = llm_service.analyze_with_tools(test_input)\n",
        "        print(\"‚úÖ Agent Response:\")\n",
        "        print(f\"   Score: {response.score}\")\n",
        "        print(f\"   Categories: {response.categories}\")\n",
        "        print(f\"   Tools used: {response.tools_used}\")\n",
        "        print(f\"   Reasoning: {response.reasoning[:300]}...\")\n",
        "        \n",
        "        if response.trace:\n",
        "            print(f\"\\n   Trace keys: {list(response.trace.keys())}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No tools defined yet. Agent mode test skipped.\")\n",
        "    print(\"   Define TOOL_DEFINITIONS in app/services/tools/definitions.py\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'started_at': '2026-01-09T19:48:13.495993',\n",
              " 'model': 'openai/gpt-5.2',\n",
              " 'mode': 'agent',\n",
              " 'input': {'input_text': 'Document contains personal information about Ahmed Ivanov including contact details and identification numbers',\n",
              "  'context': None},\n",
              " 'tool_calls': [{'tool': 'lookup_database',\n",
              "   'arguments': {'query': 'Ahmed Ivanov'},\n",
              "   'result': '{\"found\": false, \"query\": \"Ahmed Ivanov\", \"table\": null, \"message\": \"No results found for \\'Ahmed Ivanov\\'\"}',\n",
              "   'status': 'success'}],\n",
              " 'total_iterations': 2,\n",
              " 'completed_at': '2026-01-09T19:48:18.107434'}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.trace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test Full Pipeline (Processor)\n",
        "\n",
        "This is what Streamlit does behind the scenes - the complete analysis flow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing as user: usr_003 (role: UserRole.ANALYST)\n",
            "  Permissions: ['view', 'view_sensitive', 'analyze']\n",
            "  Group: group_a\n"
          ]
        }
      ],
      "source": [
        "# Get a test user for RBAC\n",
        "user = get_current_user(\"analyst_a\")\n",
        "print(f\"Testing as user: {user.id} (role: {user.role})\")\n",
        "print(f\"  Permissions: {[p.value for p in ROLE_PERMISSIONS.get(user.role, set())]}\")\n",
        "print(f\"  Group: {user.group.value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing request...\n",
            "  Input: Internal document contains sensitive personal information about Elena Volkova including full address, phone number, and date of birth\n",
            "  Context: High-risk data exposure scenario\n",
            "\n",
            "‚úÖ Pipeline completed!\n",
            "\n",
            "üìã Request (ID: 3)\n",
            "   Input: Internal document contains sensitive personal information about Elena Volkova in...\n",
            "   Group: group_a\n",
            "\n",
            "üìä Analysis Result (ID: 1)\n",
            "   Score: 92\n",
            "   Categories: ['Personally Identifiable Information (PII)', 'Sensitive Data Exposure', 'Privacy/Compliance Risk', 'Internal Document Handling', 'Data Loss Prevention (DLP)']\n",
            "   Summary: The input indicates an internal document contains sensitive personal information about an identifiable individual (Elena Volkova), specifically full address, phone number, and date of birth. These ele...\n",
            "   Model: openai/gpt-5.2\n",
            "   Validation: PASS\n",
            "\n",
            "üîç LLM Trace:\n",
            "   Keys: ['started_at', 'model', 'mode', 'input', 'completed_at', 'raw_response_preview']\n"
          ]
        }
      ],
      "source": [
        "# Run full analysis pipeline\n",
        "test_data = RequestCreate(\n",
        "    input_text=\"Internal document contains sensitive personal information about Elena Volkova including full address, phone number, and date of birth\",\n",
        "    context=\"High-risk data exposure scenario\",\n",
        "    group=\"default\",\n",
        ")\n",
        "\n",
        "print(f\"Processing request...\")\n",
        "print(f\"  Input: {test_data.input_text}\")\n",
        "print(f\"  Context: {test_data.context}\\n\")\n",
        "\n",
        "with get_session() as session:\n",
        "    processor = Processor(session, user=user)\n",
        "    \n",
        "    try:\n",
        "        request, result = processor.process_request(test_data)\n",
        "        \n",
        "        print(\"‚úÖ Pipeline completed!\")\n",
        "        print(f\"\\nüìã Request (ID: {request.id})\")\n",
        "        print(f\"   Input: {request.input_text[:80]}...\")\n",
        "        print(f\"   Group: {request.group}\")\n",
        "        \n",
        "        print(f\"\\nüìä Analysis Result (ID: {result.id})\")\n",
        "        print(f\"   Score: {result.score}\")\n",
        "        print(f\"   Categories: {result.categories}\")\n",
        "        print(f\"   Summary: {result.summary[:200]}...\")\n",
        "        print(f\"   Model: {result.model_version}\")\n",
        "        print(f\"   Validation: {result.validation_status}\")\n",
        "        \n",
        "        if result.llm_trace:\n",
        "            print(f\"\\nüîç LLM Trace:\")\n",
        "            print(f\"   Keys: {list(result.llm_trace.keys())}\")\n",
        "            if \"tools_called\" in result.llm_trace:\n",
        "                print(f\"   Tools called: {result.llm_trace['tools_called']}\")\n",
        "                \n",
        "    except PermissionError as e:\n",
        "        print(f\"‚ùå Permission denied: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test RBAC/ABAC (Different Users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available mock users:\n",
            "\n",
            "  admin_default:\n",
            "    Role: UserRole.ADMIN\n",
            "  Permissions: ['view_sensitive', 'view', 'analyze', 'export_data', 'view_all_groups', 'manage_users']\n",
            "    Groups: Group.DEFAULT\n",
            "\n",
            "  senior_default:\n",
            "    Role: UserRole.SENIOR_ANALYST\n",
            "  Permissions: ['view_sensitive', 'view', 'analyze', 'export_data', 'view_all_groups']\n",
            "    Groups: Group.DEFAULT\n",
            "\n",
            "  analyst_a:\n",
            "    Role: UserRole.ANALYST\n",
            "  Permissions: ['view', 'view_sensitive', 'analyze']\n",
            "    Groups: Group.GROUP_A\n",
            "\n",
            "  analyst_b:\n",
            "    Role: UserRole.ANALYST\n",
            "  Permissions: ['view', 'view_sensitive', 'analyze']\n",
            "    Groups: Group.GROUP_B\n",
            "\n",
            "  viewer_a:\n",
            "    Role: UserRole.VIEWER\n",
            "  Permissions: ['view']\n",
            "    Groups: Group.GROUP_A\n"
          ]
        }
      ],
      "source": [
        "# List all available mock users\n",
        "print(\"Available mock users:\")\n",
        "for user_key, user in MOCK_USERS.items():\n",
        "    print(f\"\\n  {user_key}:\")\n",
        "    print(f\"    Role: {user.role}\")\n",
        "    print(f\"  Permissions: {[p.value for p in ROLE_PERMISSIONS.get(user.role, set())]}\")\n",
        "    print(f\"    Groups: {user.group}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing as VIEWER: usr_005\n",
            "  Permissions: ['view']\n",
            "‚úÖ Correctly blocked: Access denied. User 'Eve Viewer (Group A)' with role 'viewer' does not have permission 'analyze'.\n"
          ]
        }
      ],
      "source": [
        "# Test RBAC - viewer should NOT be able to analyze\n",
        "from app.services.auth_mock import Permission\n",
        "\n",
        "\n",
        "viewer = get_current_user(\"viewer_a\")\n",
        "print(f\"Testing as VIEWER: {viewer.id}\")\n",
        "print(f\"  Permissions: {[p.value for p in ROLE_PERMISSIONS.get(user.role, set[Permission]())]}\")\n",
        "\n",
        "with get_session() as session:\n",
        "    processor = Processor(session, user=viewer)\n",
        "    \n",
        "    try:\n",
        "        request, result = processor.process_request(RequestCreate(\n",
        "            input_text=\"Test document content\",\n",
        "        ))\n",
        "        print(\"‚ùå Should have failed! Viewer shouldn't be able to analyze.\")\n",
        "    except PermissionError as e:\n",
        "        print(f\"‚úÖ Correctly blocked: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyst A groups: Group.GROUP_A\n",
            "Analyst B groups: Group.GROUP_B\n",
            "\n",
            "Analyst A sees 1 results\n",
            "Analyst B sees 0 results\n",
            "Analyst A result groups: {'group_a'}\n"
          ]
        }
      ],
      "source": [
        "# Test ABAC - analysts only see their group's data\n",
        "analyst_a = get_current_user(\"analyst_a\")\n",
        "analyst_b = get_current_user(\"analyst_b\")\n",
        "\n",
        "print(f\"Analyst A groups: {analyst_a.group}\")\n",
        "print(f\"Analyst B groups: {analyst_b.group}\")\n",
        "\n",
        "with get_session() as session:\n",
        "    processor_a = Processor(session, user=analyst_a)\n",
        "    results_a = processor_a.get_recent_results(limit=10)\n",
        "    \n",
        "    processor_b = Processor(session, user=analyst_b)\n",
        "    results_b = processor_b.get_recent_results(limit=10)\n",
        "    \n",
        "    print(f\"\\nAnalyst A sees {len(results_a)} results\")\n",
        "    print(f\"Analyst B sees {len(results_b)} results\")\n",
        "    \n",
        "    if results_a:\n",
        "        print(f\"Analyst A result groups: {set(r.group for r in results_a)}\")\n",
        "    if results_b:\n",
        "        print(f\"Analyst B result groups: {set(r.group for r in results_b)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test Validation / Guardrails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation status: PASS\n",
            "Details: None\n",
            "Passed: True\n"
          ]
        }
      ],
      "source": [
        "# Test validation functions directly\n",
        "from app.services.llm_service import LLMResponse\n",
        "\n",
        "# Create mock LLM response WITH potential PII leakage\n",
        "mock_response = LLMResponse(\n",
        "    score=75,\n",
        "    categories=[\"sensitive_data\", \"high_risk\"],\n",
        "    reasoning=\"This document contains sensitive personal information. The individual's SSN is 123-45-6789.\",\n",
        ")\n",
        "\n",
        "original_input = \"Document from John Smith\"\n",
        "\n",
        "result = run_all_validations(\n",
        "    response_text=mock_response.reasoning,\n",
        "    score=mock_response.score,              \n",
        "    categories=mock_response.categories\n",
        ")\n",
        "\n",
        "print(f\"Validation status: {result.status}\")\n",
        "print(f\"Details: {result.details}\")\n",
        "print(f\"Passed: {result.passed}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Scenarios (E2E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined 4 test scenarios:\n",
            "  1. Clean Document - Expected: LOW\n",
            "  2. Partial PII Exposure - Expected: MEDIUM\n",
            "  3. Restricted Entity Match - Expected: CRITICAL\n",
            "  4. Sensitive Person Data - Expected: HIGH\n"
          ]
        }
      ],
      "source": [
        "# Define test scenarios for content analysis\n",
        "TEST_SCENARIOS = [\n",
        "    {\n",
        "        \"name\": \"Clean Document\",\n",
        "        \"input\": \"General customer service email from ABC Corp regarding product inquiry\",\n",
        "        \"expected_risk\": \"LOW\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Partial PII Exposure\",\n",
        "        \"input\": \"Customer support ticket contains name and email address for monthly subscription inquiry\",\n",
        "        \"expected_risk\": \"MEDIUM\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Restricted Entity Match\",\n",
        "        \"input\": \"Document contains personal information about Ahmed Ivanov including full contact details and identification numbers\",\n",
        "        \"expected_risk\": \"CRITICAL\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Sensitive Person Data\",\n",
        "        \"input\": \"Internal document includes comprehensive personal information about Elena Volkova: full address, phone number, date of birth, and employment details\",\n",
        "        \"expected_risk\": \"HIGH\",\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"Defined {len(TEST_SCENARIOS)} test scenarios:\")\n",
        "for i, scenario in enumerate(TEST_SCENARIOS, 1):\n",
        "    print(f\"  {i}. {scenario['name']} - Expected: {scenario['expected_risk']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Test RAG (Retrieval-Augmented Generation)\n",
        "\n",
        "RAG uses pgvector to find similar historical cases based on semantic similarity.\n",
        "This feature can be disabled with `RAG_ENABLED=false`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.services.rag_service import calculate_similarity\n",
        "from app.services.rag_service import get_rag_service\n",
        "\n",
        "with get_session() as session:\n",
        "    rag_service = get_rag_service(session)\n",
        "\n",
        "    text_1 = \"Welcome powerpoint presentation\"\n",
        "    text_2 = \"Customer John Smith requested password reset for account A12345\"\n",
        "    embedding_1 = rag_service.get_embedding(text_1)\n",
        "    embedding_2 = rag_service.get_embedding(text_2)\n",
        "\n",
        "    distance, similarity_pct = calculate_similarity(embedding_1, embedding_2)\n",
        "\n",
        "    print(f\"Cosine distance: {distance:.4f}\")\n",
        "    print(f\"Similarity: {similarity_pct:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAG Enabled: True\n",
            "Embedding Model: text-embedding-3-small\n",
            "Embedding Dimensions: 1536\n",
            "pgvector Available: True\n"
          ]
        }
      ],
      "source": [
        "# Check if RAG is enabled and available\n",
        "from app.services.rag_service import RAGService, get_rag_service\n",
        "from app.services.secret_manager import get_settings\n",
        "\n",
        "settings = get_settings()\n",
        "print(f\"RAG Enabled: {settings.rag_enabled}\")\n",
        "print(f\"Embedding Model: {settings.embedding_model}\")\n",
        "print(f\"Embedding Dimensions: {settings.embedding_dimensions}\")\n",
        "\n",
        "# Check pgvector availability\n",
        "from app.models import PGVECTOR_AVAILABLE\n",
        "print(f\"pgvector Available: {PGVECTOR_AVAILABLE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing embedding generation...\n",
            "Input: Customer support email requesting account information update\n",
            "\n",
            "‚úÖ Embedding generated successfully!\n",
            "   Dimensions: 1536\n",
            "   First 5 values: [0.05845680832862854, -0.015425351448357105, 0.02822798863053322, -0.0036467909812927246, 0.0382862351834774]\n"
          ]
        }
      ],
      "source": [
        "# Test embedding generation directly\n",
        "with get_session() as session:\n",
        "    rag_service = get_rag_service(session)\n",
        "    \n",
        "    if rag_service.is_enabled:\n",
        "        test_text = \"Customer support email requesting account information update\"\n",
        "        \n",
        "        print(f\"Testing embedding generation...\")\n",
        "        print(f\"Input: {test_text}\\n\")\n",
        "        \n",
        "        try:\n",
        "            embedding = rag_service.get_embedding(test_text)\n",
        "            print(f\"‚úÖ Embedding generated successfully!\")\n",
        "            print(f\"   Dimensions: {len(embedding)}\")\n",
        "            print(f\"   First 5 values: {embedding[:5]}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error generating embedding: {e}\")\n",
        "            print(\"   Make sure OPENAI_API_KEY is set in your environment\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è RAG is disabled. Set RAG_ENABLED=true to test embeddings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating test cases with embeddings...\n",
            "\n",
            "RAG enabled: True\n",
            "\n",
            "Processing case 1: Customer John Smith requested password reset for a...\n",
            "   ‚úÖ Result 2 created, Score: 35, Has embedding: True\n",
            "Processing case 2: Suspicious login attempt detected for user account...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation failed for request 5: FAIL_LOW_QUALITY - Uncertainty detected: 'unknown'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Result 3 created, Score: 68, Has embedding: True\n",
            "Processing case 3: Internal memo regarding employee salary informatio...\n",
            "   ‚úÖ Result 4 created, Score: 62, Has embedding: True\n",
            "\n",
            "‚úÖ Created 3 results for similarity testing\n"
          ]
        }
      ],
      "source": [
        "# Test full pipeline with embedding generation\n",
        "# This creates analysis results WITH embeddings for similarity search\n",
        "\n",
        "user = get_current_user(\"analyst_a\")\n",
        "\n",
        "# Create several test cases for RAG to search through\n",
        "test_cases = [\n",
        "    {\n",
        "        \"input\": \"Customer John Smith requested password reset for account A12345\",\n",
        "        \"context\": \"Password reset scenario\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Suspicious login attempt detected for user account from unknown IP address\",\n",
        "        \"context\": \"Security alert scenario\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Internal memo regarding employee salary information and benefits\",\n",
        "        \"context\": \"HR document scenario\",\n",
        "    },\n",
        "]\n",
        "\n",
        "print(\"Creating test cases with embeddings...\\n\")\n",
        "\n",
        "created_results = []\n",
        "with get_session() as session:\n",
        "    processor = Processor(session, user=user)\n",
        "    \n",
        "    # Check if RAG is enabled\n",
        "    print(f\"RAG enabled: {processor.is_rag_enabled()}\\n\")\n",
        "    \n",
        "    for i, case in enumerate(test_cases, 1):\n",
        "        print(f\"Processing case {i}: {case['input'][:50]}...\")\n",
        "        \n",
        "        try:\n",
        "            request, result = processor.process_request(RequestCreate(\n",
        "                input_text=case[\"input\"],\n",
        "                context=case[\"context\"],\n",
        "            ))\n",
        "            \n",
        "            created_results.append(result)\n",
        "            \n",
        "            # Check if embedding was created\n",
        "            has_embedding = result.embedding is not None and len(result.embedding) > 0\n",
        "            print(f\"   ‚úÖ Result {result.id} created, Score: {result.score}, Has embedding: {has_embedding}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error: {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Created {len(created_results)} results for similarity testing\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Searching for similar cases...\n",
            "Query: Welcome powerpoint presentation\n",
            "\n",
            "‚úÖ Found 3 similar cases:\n",
            "\n",
            "  1. Result ID: 7\n",
            "     Score: 5\n",
            "     Categories: ['Document/File Description', 'Presentation', 'Low Information Content']\n",
            "     Summary: The input is a brief, generic description indicating a 'Welcome' PowerPoint presentation with the ad...\n",
            "\n",
            "  2. Result ID: 4\n",
            "     Score: 8\n",
            "     Categories: ['Document type: presentation', 'General/benign content', 'Low informational density']\n",
            "     Summary: The input consists of a short title-like phrase: \"Welcome presentation\" with an added note indicatin...\n",
            "\n",
            "  3. Result ID: 3\n",
            "     Score: 62\n",
            "     Categories: ['HR/Employment', 'Compensation & Benefits', 'Confidential/Proprietary Information', 'Personal Data (PII) - Potential', 'Internal Communications']\n",
            "     Summary: The input describes an internal HR memo focused on employee salary information and benefits. This ty...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test similarity search\n",
        "# Search for cases similar to a new query\n",
        "\n",
        "test_query = \"Welcome powerpoint presentation\"\n",
        "\n",
        "print(f\"üîç Searching for similar cases...\")\n",
        "print(f\"Query: {test_query}\\n\")\n",
        "\n",
        "with get_session() as session:\n",
        "    rag_service = get_rag_service(session)\n",
        "    \n",
        "    if rag_service.is_enabled:\n",
        "        try:\n",
        "            similar_cases = rag_service.find_similar_cases(\n",
        "                query_text=test_query,\n",
        "                limit=3,\n",
        "            )\n",
        "            \n",
        "            if similar_cases:\n",
        "                print(f\"‚úÖ Found {len(similar_cases)} similar cases:\\n\")\n",
        "                for i, case in enumerate(similar_cases, 1):\n",
        "                    print(f\"  {i}. Result ID: {case.id}\")\n",
        "                    print(f\"     Score: {case.score}\")\n",
        "                    print(f\"     Categories: {case.categories}\")\n",
        "                    print(f\"     Summary: {case.summary[:100]}...\")\n",
        "                    print()\n",
        "            else:\n",
        "                print(\"‚ÑπÔ∏è No similar cases found (database may be empty or no embeddings)\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error during similarity search: {e}\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è RAG is disabled. Set RAG_ENABLED=true to test similarity search.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finding cases similar to Result 4:\n",
            "   Score: 62\n",
            "   Categories: ['HR/Employment', 'Compensation & Benefits', 'Confidential/PII Risk', 'Internal Communications', 'Compliance & Policy']\n",
            "\n",
            "‚úÖ Found 3 similar cases:\n",
            "\n",
            "  1. Result ID: 1\n",
            "     Score: 92\n",
            "     Summary: The input indicates an internal document contains sensitive personal information...\n",
            "\n",
            "  2. Result ID: 2\n",
            "     Score: 35\n",
            "     Summary: The input describes a customer support/security event: a password reset request ...\n",
            "\n",
            "  3. Result ID: 3\n",
            "     Score: 68\n",
            "     Summary: The input describes a suspicious login attempt for a user account originating fr...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test finding similar cases through Processor (with ABAC filtering)\n",
        "# This demonstrates how the UI/API would use similar case search\n",
        "\n",
        "user = get_current_user(\"analyst_a\")\n",
        "\n",
        "with get_session() as session:\n",
        "    processor = Processor(session, user=user)\n",
        "    \n",
        "    # First, get the most recent result\n",
        "    recent_results = processor.get_recent_results(limit=1)\n",
        "    \n",
        "    if recent_results:\n",
        "        current_result = recent_results[0]\n",
        "        print(f\"Finding cases similar to Result {current_result.id}:\")\n",
        "        print(f\"   Score: {current_result.score}\")\n",
        "        print(f\"   Categories: {current_result.categories}\\n\")\n",
        "        \n",
        "        if processor.is_rag_enabled():\n",
        "            similar = processor.find_similar_cases(current_result, limit=3)\n",
        "            \n",
        "            if similar:\n",
        "                print(f\"‚úÖ Found {len(similar)} similar cases:\\n\")\n",
        "                for i, case in enumerate(similar, 1):\n",
        "                    print(f\"  {i}. Result ID: {case.id}\")\n",
        "                    print(f\"     Score: {case.score}\")\n",
        "                    print(f\"     Summary: {case.summary[:80]}...\")\n",
        "                    print()\n",
        "            else:\n",
        "                print(\"‚ÑπÔ∏è No similar cases found\")\n",
        "        else:\n",
        "            print(\"‚ÑπÔ∏è RAG is disabled\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è No results in database to test with\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running test scenarios...\n",
            "\n",
            "‚úÖ Clean Document\n",
            "   Expected: LOW, Got: LOW (score: 5)\n",
            "   Categories: ['Customer Service', 'Product Inquiry', 'Administrative/Meta Content', 'Low-Risk/Benign']\n",
            "   Validation: PASS\n",
            "\n",
            "‚úÖ Partial PII Exposure\n",
            "   Expected: MEDIUM, Got: MEDIUM (score: 42)\n",
            "   Categories: ['PII', 'Customer Support', 'Subscription/Billing Inquiry', 'Data Privacy']\n",
            "   Validation: PASS\n",
            "\n",
            "‚ö†Ô∏è Restricted Entity Match\n",
            "   Expected: CRITICAL, Got: HIGH (score: 72)\n",
            "   Categories: ['Personal Data / PII', 'Sensitive Identifiers', 'Contact Information', 'Restricted Entity / Watchlist Screening Context', 'Compliance / Privacy Risk']\n",
            "   Validation: PASS\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation failed for request 10: FAIL_LOW_QUALITY - Uncertainty detected: 'n/a'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Sensitive Person Data\n",
            "   Expected: HIGH, Got: CRITICAL (score: 88)\n",
            "   Categories: ['Personal Data (PII)', 'Sensitive Personal Information', 'Privacy/Confidentiality Risk', 'Internal Document Handling', 'Data Protection/Compliance']\n",
            "   Validation: FAIL_LOW_QUALITY\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run all test scenarios\n",
        "def run_test_scenario(scenario: dict, user: UserProfile):\n",
        "    \"\"\"Run a single test scenario and return results.\"\"\"\n",
        "    with get_session() as session:\n",
        "        processor = Processor(session, user=user)\n",
        "        \n",
        "        request_data = RequestCreate(\n",
        "            input_text=scenario[\"input\"],\n",
        "            context=f\"Test: {scenario['name']}\",\n",
        "        )\n",
        "        \n",
        "        request, result = processor.process_request(request_data)\n",
        "        \n",
        "        return {\n",
        "            \"name\": scenario[\"name\"],\n",
        "            \"expected\": scenario[\"expected_risk\"],\n",
        "            \"actual_score\": result.score,\n",
        "            \"categories\": result.categories,\n",
        "            \"validation\": result.validation_status,\n",
        "            \"summary\": result.summary[:100] + \"...\",\n",
        "        }\n",
        "\n",
        "# Run scenarios\n",
        "user = get_current_user(\"analyst_a\")\n",
        "\n",
        "print(\"Running test scenarios...\\n\")\n",
        "for scenario in TEST_SCENARIOS:\n",
        "    try:\n",
        "        result = run_test_scenario(scenario, user)\n",
        "        \n",
        "        # Determine risk level from score\n",
        "        score = result[\"actual_score\"]\n",
        "        if score <= 25:\n",
        "            actual_level = \"LOW\"\n",
        "        elif score <= 50:\n",
        "            actual_level = \"MEDIUM\"\n",
        "        elif score <= 75:\n",
        "            actual_level = \"HIGH\"\n",
        "        else:\n",
        "            actual_level = \"CRITICAL\"\n",
        "        \n",
        "        match = \"‚úÖ\" if actual_level == result[\"expected\"] else \"‚ö†Ô∏è\"\n",
        "        \n",
        "        print(f\"{match} {result['name']}\")\n",
        "        print(f\"   Expected: {result['expected']}, Got: {actual_level} (score: {score})\")\n",
        "        print(f\"   Categories: {result['categories']}\")\n",
        "        print(f\"   Validation: {result['validation']}\")\n",
        "        print()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {scenario['name']}: {e}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Debug Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last 5 analysis results:\n",
            "\n",
            "ID: 8 | Score: 88 | Status: FAIL_LOW_QUALITY\n",
            "   Categories: ['Personal Data (PII)', 'Sensitive Personal Information', 'Privacy/Confidentiality Risk', 'Internal Document Handling', 'Data Protection/Compliance']\n",
            "   Created: 2026-01-09 17:44:39.323043\n",
            "\n",
            "ID: 7 | Score: 72 | Status: PASS\n",
            "   Categories: ['Personal Data / PII', 'Sensitive Identifiers', 'Contact Information', 'Restricted Entity / Watchlist Screening Context', 'Compliance / Privacy Risk']\n",
            "   Created: 2026-01-09 17:44:34.184519\n",
            "\n",
            "ID: 6 | Score: 42 | Status: PASS\n",
            "   Categories: ['PII', 'Customer Support', 'Subscription/Billing Inquiry', 'Data Privacy']\n",
            "   Created: 2026-01-09 17:44:29.010817\n",
            "\n",
            "ID: 5 | Score: 5 | Status: PASS\n",
            "   Categories: ['Customer Service', 'Product Inquiry', 'Administrative/Meta Content', 'Low-Risk/Benign']\n",
            "   Created: 2026-01-09 17:44:23.161128\n",
            "\n",
            "ID: 4 | Score: 62 | Status: PASS\n",
            "   Categories: ['HR/Employment', 'Compensation & Benefits', 'Confidential/PII Risk', 'Internal Communications', 'Compliance & Policy']\n",
            "   Created: 2026-01-09 17:40:59.860275\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Helper: View recent results from DB\n",
        "from sqlmodel import select\n",
        "\n",
        "with get_session() as session:\n",
        "    stmt = select(AnalysisResult).order_by(AnalysisResult.created_at.desc()).limit(5)\n",
        "    results = session.exec(stmt).all()\n",
        "    \n",
        "    print(f\"Last {len(results)} analysis results:\\n\")\n",
        "    for r in results:\n",
        "        print(f\"ID: {r.id} | Score: {r.score} | Status: {r.validation_status}\")\n",
        "        print(f\"   Categories: {r.categories}\")\n",
        "        print(f\"   Created: {r.created_at}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM Trace for result 1:\n",
            "{\n",
            "  \"started_at\": \"2026-01-09T17:38:50.802751\",\n",
            "  \"model\": \"openai/gpt-5.2\",\n",
            "  \"mode\": \"simple\",\n",
            "  \"input\": {\n",
            "    \"input_text\": \"Internal document contains sensitive personal information about Elena Volkova including full address, phone number, and date of birth\",\n",
            "    \"context\": \"High-risk data exposure scenario\"\n",
            "  },\n",
            "  \"completed_at\": \"2026-01-09T17:38:56.324234\",\n",
            "  \"raw_response_preview\": \"{\\n  \\\"score\\\": 92,\\n  \\\"categories\\\": [\\n    \\\"Personally Identifiable Information (PII)\\\",\\n    \\\"Sensitive Data Exposure\\\",\\n    \\\"Privacy/Compliance Risk\\\",\\n    \\\"Internal Document Handling\\\",\\n    \\\"Data Loss Prevention (DLP)\\\"\\n  ],\\n  \\\"summary\\\": \\\"The input indicates an internal document contains sensitive personal information about an identifiable individual (Elena Volkova), specifically full address, phone number, and date of birth. These elements constitute high-risk PII because they can enable identity thef\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Helper: View LLM trace for a specific result\n",
        "import json\n",
        "\n",
        "result_id = 1  # Change this to inspect different results\n",
        "\n",
        "with get_session() as session:\n",
        "    result = session.get(AnalysisResult, result_id)\n",
        "    \n",
        "    if result and result.llm_trace:\n",
        "        print(f\"LLM Trace for result {result_id}:\")\n",
        "        print(json.dumps(result.llm_trace, indent=2, default=str))\n",
        "    else:\n",
        "        print(f\"No trace found for result {result_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": []
        }
      ],
      "source": [
        "# Helper: Clear all test data (use carefully!)\n",
        "# Uncomment to run\n",
        "\n",
        "from sqlmodel import text\n",
        "with get_session() as session:\n",
        "    session.exec(text(\"TRUNCATE analysis_results RESTART IDENTITY CASCADE\"))\n",
        "    session.exec(text(\"TRUNCATE requests RESTART IDENTITY CASCADE\"))\n",
        "    print(\"‚úÖ All test data cleared\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù Quick Reference\n",
        "\n",
        "### Before Starting:\n",
        "1. `docker compose up -d db` - Start database with pgvector (service name is **db**)\n",
        "2. Check LLM provider (Ollama running OR API key set)\n",
        "3. Run Setup cells (1.1 - 1.3)\n",
        "\n",
        "### Quick Validation:\n",
        "| Phase | Test Section |\n",
        "|-------|-------------|\n",
        "| Phase 1 (Models) | Section 2 |\n",
        "| Phase 2 (Tools) | Section 3 |\n",
        "| Phase 3 (Prompts) | Sections 4-5 |\n",
        "| Phase 4 (Validation) | Section 7 |\n",
        "| Phase 5 (Processor) | Section 5 |\n",
        "| Phase 6 (UI) | Streamlit browser |\n",
        "| RAG (Vector Search) | Section 9 |\n",
        "\n",
        "### Hotkeys:\n",
        "- `Shift+Enter` - Run cell and move to next\n",
        "- `Ctrl+Enter` - Run cell and stay\n",
        "- `Esc + A` - Insert cell above\n",
        "- `Esc + B` - Insert cell below\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
