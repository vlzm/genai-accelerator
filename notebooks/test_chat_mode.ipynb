{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üí¨ Chat Mode Testing Notebook\n",
        "\n",
        "This notebook tests the new **Chat Mode** feature that enables conversational Q&A\n",
        "without scoring/analysis.\n",
        "\n",
        "**Key Differences from Analysis Mode:**\n",
        "- No score is generated (`score = None`)\n",
        "- No categories are identified (`categories = []`)\n",
        "- `result_type = \"chat\"` instead of `\"analysis\"`\n",
        "- Validation is skipped (no score to validate)\n",
        "- UI displays as chat bubble instead of score card\n",
        "\n",
        "**Structure:**\n",
        "1. Setup & Imports\n",
        "2. Test LLM Service in Chat Mode\n",
        "3. Test Processor in Chat Mode\n",
        "4. Compare Analysis vs Chat Mode\n",
        "5. Test Edge Cases\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\Users\\zamko\\Documents\\vlzm\\kyc-analyzer\n"
          ]
        }
      ],
      "source": [
        "# Add project root to path\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path().absolute().parent\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment configured:\n",
            "  ENV: LOCAL\n",
            "  LLM_PROVIDER: openai\n",
            "  DATABASE: app_db @ localhost:5432\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables BEFORE imports\n",
        "import os\n",
        "\n",
        "# Required for local development\n",
        "os.environ.setdefault(\"ENV\", \"LOCAL\")\n",
        "os.environ.setdefault(\"LLM_PROVIDER\", \"openai\")  # or \"ollama\", \"azure\", \"anthropic\"\n",
        "os.environ.setdefault(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
        "os.environ.setdefault(\"OLLAMA_MODEL\", \"llama3.2\")\n",
        "\n",
        "# Database settings (matches docker-compose.yml)\n",
        "# Run: docker compose up -d db\n",
        "os.environ[\"DATABASE_HOST\"] = \"localhost\"\n",
        "os.environ[\"DATABASE_PORT\"] = \"5432\"\n",
        "os.environ[\"DATABASE_NAME\"] = \"app_db\"\n",
        "os.environ[\"DATABASE_USER\"] = \"postgres\"\n",
        "os.environ[\"DATABASE_PASSWORD\"] = \"localdevpassword123\"\n",
        "\n",
        "print(\"Environment configured:\")\n",
        "print(f\"  ENV: {os.environ['ENV']}\")\n",
        "print(f\"  LLM_PROVIDER: {os.environ['LLM_PROVIDER']}\")\n",
        "print(f\"  DATABASE: {os.environ['DATABASE_NAME']} @ {os.environ['DATABASE_HOST']}:{os.environ['DATABASE_PORT']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "# Import core modules\n",
        "from app.database import init_db, get_session\n",
        "from app.models import Request, RequestCreate, AnalysisResult\n",
        "from app.services.llm_service import get_llm_service\n",
        "from app.services.processor import Processor\n",
        "from app.services.auth_mock import get_current_user\n",
        "from app.services.llm.base import LLMResponse, CHAT_SYSTEM_PROMPT, DEFAULT_SYSTEM_PROMPT\n",
        "\n",
        "print(\"All imports successful!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Migration: Add result_type column if it doesn't exist\n",
        "# # Run this once to update the database schema for chat mode support\n",
        "# from sqlmodel import text\n",
        "\n",
        "# with get_session() as session:\n",
        "#     try:\n",
        "#         session.exec(text(\"\"\"\n",
        "#             ALTER TABLE analysis_results \n",
        "#             ADD COLUMN IF NOT EXISTS result_type VARCHAR(50) DEFAULT 'analysis'\n",
        "#         \"\"\"))\n",
        "#         session.commit()\n",
        "#         print(\"‚úÖ Migration complete: 'result_type' column added (or already exists)\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ö†Ô∏è Migration note: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Tables recreated!\n"
          ]
        }
      ],
      "source": [
        "# Drop and recreate all tables (run this if you need to reset the database schema)\n",
        "from app.database import get_engine\n",
        "from sqlmodel import SQLModel\n",
        "\n",
        "engine = get_engine()\n",
        "\n",
        "# Drop and recreate all tables\n",
        "SQLModel.metadata.drop_all(engine)\n",
        "SQLModel.metadata.create_all(engine)\n",
        "print(\"‚úÖ Tables recreated!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Database initialized!\n"
          ]
        }
      ],
      "source": [
        "# Initialize database\n",
        "init_db()\n",
        "print(\"Database initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Test LLM Service in Chat Mode\n",
        "\n",
        "Test the LLM service directly with `mode=\"chat\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM Provider: openai\n",
            "Model Version: openai/gpt-5.2\n"
          ]
        }
      ],
      "source": [
        "# Get LLM service\n",
        "llm_service = get_llm_service()\n",
        "print(f\"LLM Provider: {llm_service.provider_name}\")\n",
        "print(f\"Model Version: {llm_service.get_model_version()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "CHAT MODE RESPONSE (Simple)\n",
            "==================================================\n",
            "Score: None\n",
            "Categories: []\n",
            "Mode: chat\n",
            "\n",
            "Response:\n",
            "The capital of France is Paris.\n"
          ]
        }
      ],
      "source": [
        "# Test simple chat mode (without tools)\n",
        "chat_response = llm_service.analyze(\n",
        "    input_text=\"What is the capital of France?\",\n",
        "    mode=\"chat\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"CHAT MODE RESPONSE (Simple)\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Score: {chat_response.score}\")  # Should be None\n",
        "print(f\"Categories: {chat_response.categories}\")  # Should be []\n",
        "print(f\"Mode: {chat_response.mode}\")\n",
        "print(f\"\\nResponse:\\n{chat_response.reasoning}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "CHAT MODE RESPONSE (With Tools)\n",
            "==================================================\n",
            "Score: None\n",
            "Categories: []\n",
            "Mode: chat\n",
            "Tools Used: ['get_current_time']\n",
            "\n",
            "Response:\n",
            "Current time (UTC): 20:54:03 on Friday, 2026-01-09.\n",
            "\n",
            "Weather today: I can‚Äôt determine the weather because I don‚Äôt have your location and there‚Äôs no weather tool/API available in this environment. If you tell me your city (and country) or ZIP/postal code, I can help you figure out what to check and how (e.g., the quickest sources/apps).\n",
            "\n",
            "Trace Mode: agent_chat\n"
          ]
        }
      ],
      "source": [
        "# Test chat mode with tools (agent mode)\n",
        "chat_with_tools = llm_service.analyze_with_tools(\n",
        "    input_text=\"What time is it now? Also, what's the weather like today?\",\n",
        "    mode=\"chat\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"CHAT MODE RESPONSE (With Tools)\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Score: {chat_with_tools.score}\")  # Should be None\n",
        "print(f\"Categories: {chat_with_tools.categories}\")  # Should be []\n",
        "print(f\"Mode: {chat_with_tools.mode}\")\n",
        "print(f\"Tools Used: {chat_with_tools.tools_used}\")\n",
        "print(f\"\\nResponse:\\n{chat_with_tools.reasoning}\")\n",
        "\n",
        "if chat_with_tools.trace:\n",
        "    print(f\"\\nTrace Mode: {chat_with_tools.trace.get('mode')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test Processor in Chat Mode\n",
        "\n",
        "Test the full pipeline through the Processor with `mode=\"chat\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using user: Carol Analyst (Group A) (role: analyst)\n"
          ]
        }
      ],
      "source": [
        "# Get a test user\n",
        "test_user = get_current_user(\"analyst_a\")\n",
        "print(f\"Using user: {test_user.username} (role: {test_user.role.value})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "CHAT MODE - FULL PIPELINE RESULT\n",
            "==================================================\n",
            "Request ID: 1\n",
            "Result ID: 1\n",
            "Result Type: chat\n",
            "Score: None\n",
            "Categories: []\n",
            "Validation Status: PASS\n",
            "Validation Details: Chat mode - validation skipped\n",
            "\n",
            "AI Response:\n",
            "Machine learning is a way to make computers learn from examples instead of being explicitly programmed with every rule.\n",
            "\n",
            "### A simple way to think about it\n",
            "- **Traditional programming:** You write rules (if this, then that) and the computer follows them.\n",
            "- **Machine learning:** You give the computer **lots of examples**, and it figures out patterns on its own.\n",
            "\n",
            "### Everyday analogy\n",
            "Imagine teaching a child to recognize cats:\n",
            "- You don‚Äôt give a perfect written rule for what a cat is.\n",
            "- You show many pictures labeled **‚Äúcat‚Äù** and **‚Äúnot cat.‚Äù**\n",
            "- Over time, the child learns what features usually mean ‚Äúcat.‚Äù\n",
            "Machine learning works similarly: it learns from labeled or unlabeled examples.\n",
            "\n",
            "### What it‚Äôs used for\n",
            "Machine learning powers things like:\n",
            "- **Recommendations:** Netflix/YouTube suggesting what to watch next\n",
            "- **Spam filters:** deciding whether an email is spam\n",
            "- **Photo tagging:** recognizing faces or objects in pictures\n",
            "- **Voice assistants:** understanding speech\n",
            "- **Fraud detection:** spotting unusual credit card activity\n",
            "\n",
            "### The basic process (high level)\n",
            "1. **Collect data:** examples (like emails marked spam/not spam)\n",
            "2. **Train a model:** the computer learns patterns from the data\n",
            "3. **Make predictions:** it uses what it learned on new, unseen cases\n",
            "4. **Improve over time:** with more data and feedback, it can get better\n",
            "\n",
            "### One important note\n",
            "Machine learning doesn‚Äôt ‚Äúunderstand‚Äù like a human‚Äîit‚Äôs mainly doing **pattern recognition** based on the data it has seen. If the data is biased or incomplete, the results can be too.\n",
            "\n",
            "If you tell me what topic you‚Äôre most curious about (recommendations, images, language, etc.), I can give a very concrete example step-by-step.\n"
          ]
        }
      ],
      "source": [
        "# Test chat mode through processor\n",
        "with get_session() as session:\n",
        "    processor = Processor(session, user=test_user)\n",
        "    \n",
        "    # Create a chat request\n",
        "    request_data = RequestCreate(\n",
        "        input_text=\"Hello! Can you explain what machine learning is in simple terms?\",\n",
        "        context=\"I'm a beginner with no technical background.\",\n",
        "        group=\"group_a\"\n",
        "    )\n",
        "    \n",
        "    # Process in CHAT mode\n",
        "    request, result = processor.process_request(request_data, mode=\"chat\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"CHAT MODE - FULL PIPELINE RESULT\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Request ID: {request.id}\")\n",
        "print(f\"Result ID: {result.id}\")\n",
        "print(f\"Result Type: {result.result_type}\")\n",
        "print(f\"Score: {result.score}\")  # Should be None\n",
        "print(f\"Categories: {result.categories}\")  # Should be []\n",
        "print(f\"Validation Status: {result.validation_status}\")\n",
        "print(f\"Validation Details: {result.validation_details}\")\n",
        "print(f\"\\nAI Response:\\n{result.summary}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compare Analysis vs Chat Mode\n",
        "\n",
        "Process the same input in both modes to see the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "COMPARISON: ANALYSIS vs CHAT MODE\n",
            "============================================================\n",
            "\n",
            "üìä ANALYSIS MODE:\n",
            "  Result Type: analysis\n",
            "  Score: 72\n",
            "  Categories: ['AML/Financial Crime', 'Offshore Jurisdiction', 'Large Transaction', 'Potential Tax Evasion/Concealment Risk']\n",
            "  Validation: PASS\n",
            "  Summary (truncated): Content indicates a customer transferred $50,000 to an offshore account in the Cayman Islands. This combination (material amount + offshore destination commonly associated with secrecy/asset shielding...\n",
            "\n",
            "üí¨ CHAT MODE:\n",
            "  Result Type: chat\n",
            "  Score: None\n",
            "  Categories: []\n",
            "  Validation: PASS\n",
            "  Response (truncated): Potential concerns (AML/financial crime) with a $50,000 transfer to an offshore account in the Cayman Islands include:\n",
            "\n",
            "1) Offshore/high-risk jurisdiction considerations\n",
            "- Cayman Islands is a well-kno...\n"
          ]
        }
      ],
      "source": [
        "# Same input text for comparison\n",
        "test_input = \"The customer transferred $50,000 to an offshore account in the Cayman Islands.\"\n",
        "\n",
        "with get_session() as session:\n",
        "    processor = Processor(session, user=test_user)\n",
        "    \n",
        "    # ANALYSIS MODE\n",
        "    analysis_request = RequestCreate(\n",
        "        input_text=test_input,\n",
        "        group=\"group_a\"\n",
        "    )\n",
        "    req_analysis, result_analysis = processor.process_request(analysis_request, mode=\"analysis\")\n",
        "    \n",
        "    # CHAT MODE\n",
        "    chat_request = RequestCreate(\n",
        "        input_text=f\"What are the potential concerns with this transaction: {test_input}\",\n",
        "        group=\"group_a\"\n",
        "    )\n",
        "    req_chat, result_chat = processor.process_request(chat_request, mode=\"chat\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPARISON: ANALYSIS vs CHAT MODE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüìä ANALYSIS MODE:\")\n",
        "print(f\"  Result Type: {result_analysis.result_type}\")\n",
        "print(f\"  Score: {result_analysis.score}\")\n",
        "print(f\"  Categories: {result_analysis.categories}\")\n",
        "print(f\"  Validation: {result_analysis.validation_status}\")\n",
        "print(f\"  Summary (truncated): {result_analysis.summary[:200]}...\")\n",
        "\n",
        "print(\"\\nüí¨ CHAT MODE:\")\n",
        "print(f\"  Result Type: {result_chat.result_type}\")\n",
        "print(f\"  Score: {result_chat.score}\")\n",
        "print(f\"  Categories: {result_chat.categories}\")\n",
        "print(f\"  Validation: {result_chat.validation_status}\")\n",
        "print(f\"  Response (truncated): {result_chat.summary[:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test Edge Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "CHAT WITH CONTEXT\n",
            "==================================================\n",
            "Result Type: chat\n",
            "Score: None\n",
            "\n",
            "Response:\n",
            "Next steps (wire-fraud/AML triage) for 5 international wires in one day:\n",
            "\n",
            "1) Contain risk immediately\n",
            "- Place a temporary hold / enhanced review on any pending or not-yet-released wires.\n",
            "- If any wires have already been sent, initiate wire recall/trace requests with your bank/operations team ASAP (speed matters).\n",
            "- Consider temporarily restricting additional outbound wires on the account until review is complete.\n",
            "\n",
            "2) Gather the transaction facts (build a quick case file)\n",
            "- For each of the 5 wires: amount, currency, date/time, beneficiary name, beneficiary bank, country, SWIFT/BIC, purpose/notes, channel used (online/branch/API), and who approved/released.\n",
            "- Pull customer profile: KYC info, expected activity, occupation/business, source of funds, historical wire patterns, prior alerts/cases.\n",
            "- Check for red flags: first-time beneficiaries, high-risk jurisdictions, structuring (split amounts), urgency language, ‚Äúconsulting/investment/crypto‚Äù narratives, mismatched beneficiary names, round-dollar amounts, recent account changes.\n",
            "\n",
            "3) Verify customer intent and account integrity\n",
            "- Contact the customer using a trusted callback method (not the number/email provided in the wire instructions).\n",
            "- Confirm: did they authorize all 5 wires, why multiple countries, relationship to beneficiaries, invoices/contracts, and source of funds.\n",
            "- Ask about compromise indicators: recent phishing, remote-access software, SIM swap, email takeover, new device login, password reset.\n",
            "\n",
            "4) Perform screening and risk checks\n",
            "- Sanctions/PEP/adverse media screening on: customer, each beneficiary, and beneficiary banks (as applicable).\n",
            "- Country risk assessment for each destination (high-risk/OFAC/AML concerns).\n",
            "- Internal fraud signals: new device/IP, unusual login geo, velocity spikes, changes to contact details, failed login attempts.\n",
            "\n",
            "5) Request supporting documentation (proportional to risk)\n",
            "- Invoices/contracts, proof of relationship, business rationale, shipping docs (if trade), and evidence of services.\n",
            "- Source-of-funds/source-of-wealth evidence if amounts are material or inconsistent with profile.\n",
            "\n",
            "6) Decide disposition (clear, escalate, or exit)\n",
            "- If consistent with profile and well-documented: document rationale and release/close alert.\n",
            "- If inconsistent, unverifiable, or compromise suspected: keep holds, escalate to fraud/AML investigations, consider account lock/reset credentials, and consider returning/recalling funds.\n",
            "\n",
            "7) Regulatory/mandatory reporting (coordinate with compliance)\n",
            "- If suspicion remains: prepare and file the appropriate suspicious activity report (SAR/STR) per your jurisdiction and internal policy, within required timelines.\n",
            "- Preserve evidence: call notes, screenshots, logs, documents, and decisioning.\n",
            "\n",
            "8) Customer protection actions (if fraud/ATO suspected)\n",
            "- Force credential reset, add step-up authentication, review authorized users, and update contact info securely.\n",
            "- Educate customer on common scams (investment/romance/business email compromise) relevant to what you learn.\n",
            "\n",
            "If you share: (a) the destination countries, (b) amounts, (c) whether these were first-time beneficiaries, and (d) whether the customer‚Äôs profile normally supports international wires, I can help you prioritize which red flags to focus on and what questions/docs to request first.\n"
          ]
        }
      ],
      "source": [
        "# Test chat with context\n",
        "with get_session() as session:\n",
        "    processor = Processor(session, user=test_user)\n",
        "    \n",
        "    request_data = RequestCreate(\n",
        "        input_text=\"What should I do next?\",\n",
        "        context=\"I'm reviewing a suspicious transaction from yesterday. The customer made 5 wire transfers to different countries.\",\n",
        "        group=\"group_a\"\n",
        "    )\n",
        "    \n",
        "    request, result = processor.process_request(request_data, mode=\"chat\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"CHAT WITH CONTEXT\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Result Type: {result.result_type}\")\n",
        "print(f\"Score: {result.score}\")\n",
        "print(f\"\\nResponse:\\n{result.summary}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "CHAT MODE - VALIDATION SKIPPED\n",
            "==================================================\n",
            "Result Type: chat\n",
            "Validation Status: PASS\n",
            "Validation Details: Chat mode - validation skipped\n",
            "\n",
            "Note: In analysis mode, this might fail validation.\n",
            "In chat mode, validation is skipped.\n"
          ]
        }
      ],
      "source": [
        "# Test that chat mode skips validation properly\n",
        "with get_session() as session:\n",
        "    processor = Processor(session, user=test_user)\n",
        "    \n",
        "    # Short input that would fail quality validation in analysis mode\n",
        "    request_data = RequestCreate(\n",
        "        input_text=\"Hi\",\n",
        "        group=\"group_a\"\n",
        "    )\n",
        "    \n",
        "    request, result = processor.process_request(request_data, mode=\"chat\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"CHAT MODE - VALIDATION SKIPPED\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Result Type: {result.result_type}\")\n",
        "print(f\"Validation Status: {result.validation_status}\")\n",
        "print(f\"Validation Details: {result.validation_details}\")\n",
        "print(f\"\\nNote: In analysis mode, this might fail validation.\")\n",
        "print(f\"In chat mode, validation is skipped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "LLMResponse MODEL TEST\n",
            "==================================================\n",
            "Score: None\n",
            "Score is None: True\n",
            "Categories: []\n",
            "Mode: chat\n",
            "\n",
            "‚úÖ LLMResponse correctly accepts None score for chat mode!\n"
          ]
        }
      ],
      "source": [
        "# Verify LLMResponse model accepts None score\n",
        "from app.services.llm.base import LLMResponse\n",
        "\n",
        "# This should work without errors\n",
        "test_response = LLMResponse(\n",
        "    score=None,\n",
        "    categories=[],\n",
        "    reasoning=\"This is a test response\",\n",
        "    mode=\"chat\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"LLMResponse MODEL TEST\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Score: {test_response.score}\")\n",
        "print(f\"Score is None: {test_response.score is None}\")\n",
        "print(f\"Categories: {test_response.categories}\")\n",
        "print(f\"Mode: {test_response.mode}\")\n",
        "print(\"\\n‚úÖ LLMResponse correctly accepts None score for chat mode!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. View System Prompts\n",
        "\n",
        "Compare the system prompts used for each mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ANALYSIS MODE SYSTEM PROMPT\n",
            "============================================================\n",
            "You are a helpful AI assistant specialized in analyzing and processing text.\n",
            "\n",
            "Your task is to analyze the provided input and:\n",
            "1. Assess the content based on relevant criteria\n",
            "2. Identify key categories or themes\n",
            "3. Provide a clear summary of your analysis\n",
            "4. Optionally, provide processed/transformed content\n",
            "\n",
            "Scoring Guidelines:\n",
            "- LOW (0-25): Minimal significance or concern\n",
            "- MEDIUM (26-50): Moderate significance, may need attention\n",
            "- HIGH (51-75): Significant findings, requires review\n",
            "- CRITICAL (76-100): Critical findings, immediate action recommended\n",
            "\n",
            "Always respond in valid JSON format with the following structure:\n",
            "{\n",
            "    \"score\": <integer 0-100>,\n",
            "    \"categories\": [\"<category1>\", \"<category2>\", ...],\n",
            "    \"summary\": \"<detailed analysis and reasoning>\",\n",
            "    \"processed_content\": \"<optional transformed content>\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"ANALYSIS MODE SYSTEM PROMPT\")\n",
        "print(\"=\" * 60)\n",
        "print(DEFAULT_SYSTEM_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CHAT MODE SYSTEM PROMPT\n",
            "============================================================\n",
            "You are a helpful AI assistant. Your goal is to provide clear, accurate, and helpful responses to user questions.\n",
            "\n",
            "You have access to tools that can help you gather information. Use them when needed.\n",
            "\n",
            "When responding:\n",
            "1. Be concise but thorough\n",
            "2. If you're uncertain, say so\n",
            "3. Provide actionable information when possible\n",
            "\n",
            "You MUST always respond in valid JSON format with the following structure:\n",
            "{\n",
            "    \"reasoning\": \"<your detailed answer here>\",\n",
            "    \"score\": null,\n",
            "    \"categories\": []\n",
            "}\n",
            "\n",
            "Important: In chat mode, score is always null and categories is always empty. Put your full response in the \"reasoning\" field.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"CHAT MODE SYSTEM PROMPT\")\n",
        "print(\"=\" * 60)\n",
        "print(CHAT_SYSTEM_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary\n",
        "\n",
        "The chat mode feature enables:\n",
        "\n",
        "1. **Conversational Q&A** - Users can ask questions without triggering scoring\n",
        "2. **Flexible Responses** - No need to generate score/categories\n",
        "3. **Same Infrastructure** - Uses the same tools, RAG, and tracing\n",
        "4. **Skipped Validation** - No score validation in chat mode\n",
        "5. **Different UI** - Results displayed as chat bubbles instead of score cards\n",
        "\n",
        "**Key Code Changes:**\n",
        "- `models.py`: `score` is now `Optional[int]`, added `result_type` field\n",
        "- `base.py`: Added `CHAT_SYSTEM_PROMPT`, updated `LLMResponse` and parsing\n",
        "- `processor.py`: Added `mode` parameter to `analyze_request()` and `process_request()`\n",
        "- `main.py`: Added mode selector in UI, conditional rendering based on `result_type`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
